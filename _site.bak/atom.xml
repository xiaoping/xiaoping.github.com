<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>百度运维团队技术博客</title>
 <link href="http://www.baidu-ops.com/atom.xml" rel="self"/>
 <link href="http://www.baidu-ops.com"/>
 <updated>2012-12-09T16:46:15+01:00</updated>
 <id>http://www.baidu-ops.com</id>
 <author>
   <name>zerd liu</name>
   <email>zerdliu@126.com</email>
 </author>

 
 <entry>
   <title>[译文]Release Engineering at Facebook</title>
   <link href="http://www.baidu-ops.com/2012/12/07/release-engineering-at-facebook"/>
   <updated>2012-12-07T00:00:00+01:00</updated>
   <id>http://www.baidu-ops.com/2012/12/07/release-engineering-at-facebook</id>
   <content type="html">&lt;p&gt;&lt;a href='http://devops.com/2012/11/08/release-engineering-at-facebook/'&gt;原文地址&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;本文是来自Facebook的软件发布工程师 &lt;a href='https://twitter.com/chuckr'&gt;Chuck Rossi&lt;/a&gt; 在&lt;a href='http://qconsf.com/sf2012/'&gt;QConSF 2012&lt;/a&gt; 上的一次演讲。&lt;/p&gt;

&lt;p&gt;twitter： &lt;a href='https://twitter.com/chuckr'&gt;@mattokeefe&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Chuck本人其实不愿提及以“D”或“O”打头的那个词 “DevOps, 但自从John Allspaw（Etsy的OP高级副总裁,前Flickr工程师）在Velocity09年大会上做了 &lt;a href='http://www.youtube.com/watch?v=LdOe18KhtT4'&gt;“10+ Deploys Per Day: Dev and Ops Cooperation at Flickr“&lt;/a&gt;的演讲后，他便从此被打动了。这也使得他在Facebook组建起一个关于开发和运维合作的训练营，因此他的演讲中尽是对新开发人员的培训内容。&lt;/p&gt;

&lt;h2 id='id173'&gt;面临的问题&lt;/h2&gt;

&lt;p&gt;开发人员想要尽可能快的产出代码成品，发布工程师也不希望有任何打断，因此便产生了一个流程需求。“我可以发布的更快么”，“不行，你走开”。这样当然不行啦，于是开发人员和发布工程师努力开始进行改变。 Facebook本身的迭代速度几近疯狂，而且其规模（服务和基础设施）巨大，世界上几乎没有那家公司在这样大规模的情况下还向前发展（迭代）得这么快。&lt;/p&gt;

&lt;p&gt;在Chuck的处理方式中有两件法宝：工具和文化（译注：这也是DevOps的核心原则）。 他在听过Allspaw的演讲后认真理解了所谓的“文化”，他对开发人员宣灌的第一件事情就是：他们将把自己的对程序的改变呈献给全世界，如果他们写完代码就把其抛过墙去（译注：DevOps理念强调的Dev与Ops之间隔阂的那堵墙），这将直接影响Chuck的Mom（译注：意味着就连发布者们的妈妈都会因为使用Facebook，而第一时间感受到业务的升级）。因此开发人员应尽的职责包括不得不进行一些基础的工作，并且把代码Check-in到主干。要知道在Facebook并没有QA团队在程序发布前去帮你发现其中的Bug。&lt;/p&gt;

&lt;p&gt;那么你该如何去做呢？你需要知道什么时候，什么样子表示你的发布完成了。Facebook的所有系统的发布都遵循这样的规则或路径，日复一日。&lt;/p&gt;

&lt;h2 id='facebook'&gt;FaceBook是如何做提交的？&lt;/h2&gt;

&lt;p&gt;Chuck并不关心你的源代码控制系统是什么？因为他讨厌所有的源代码控制系统。他们从主干进行发布（译注：通常会拉出Release Branch做发布），每周日下午6点，从主干拉出“最新”的分支，接下来的两天进行发布前的测试。不过那都是过去了， 现在他们在周二发布，周三至周五选择需要做的改进，每天差不多有50-300项改进被整合进去。&lt;/p&gt;

&lt;p&gt;但是，Chuck觉得这样还不够，他在Facebook engineering blog上发表的&lt;a href='https://www.facebook.com/notes/facebook-engineering/ship-early-and-ship-twice-as-often/10150985860363920'&gt;“Ship early and ship twice as often”&lt;/a&gt;一文表明了这一点。 2012年8月份的时候他们每天可以发布的变更是过去的两倍了。这种疯狂是一些人不能想象的，因为尽管现在每天的改进数量没变但改进本身比以前小得多了。&lt;/p&gt;

&lt;p&gt;现在每周差不多有800个开发人员check-in代码，并且随着雇员的增加还会增长。每个月差不多有10K次的代码提交，但是每天的发布占比还是很稳定的。 产品发布是有节奏的， 因此你应该把主要精力投入到每周级别的大发布中.(译注：Facebook的发布是按规律每周工作日做不同级别的发布，有的是周级别的大型发布，有的则是天级别的小型发布) &lt;br /&gt;要小心周五的发布,要知道在Google可有“逢周五不发布”的传统。不要把代码提交到主干后就溜掉了，要知道周日和周一可是Facebook的大日子，因为人们习惯这个时候上传和查看周末的照片。&lt;/p&gt;

&lt;p&gt;如果你不记得该如何去发布，千万不要做任何事情。仅仅check in代码到主干，你就能避免日常发布中的操作负担。&lt;/p&gt;

&lt;p&gt;要记住你不是今天唯一做发布的团队，把小的修改整合在一起，以至于你可以看到公司层面的发布计划，在Facebook他们专门建立facebook组群用做改进的整合。&lt;/p&gt;

&lt;h2 id='dogfooding'&gt;Dogfooding&lt;/h2&gt;

&lt;p&gt;“你应该时刻保持被测试”，这一点虽然人们老是提起但并不是真正理解，但是Facebook却是很认真对待测试。 员工们从来不可能直接影响 facebook.com 主站， 因为他们所有改变将被重定向到 www.latest.facebook.com. 这个站是线上实际生产环境加上所有提交的改变，因此整个公司可以看到做了哪些改动。如果有任何的致命错误，你甚至可以直达bug报告页面。&lt;/p&gt;

&lt;p&gt;当你能浮现Bug的时候把它归档，让内部人员在上报错误的时候更容易更顺畅。 Facebook内部页面将包含一些捕获会话状态的按钮，可以帮你把bug报告给合适的人。&lt;/p&gt;

&lt;p&gt;当Chuck做发布时，还要求开发人员的修改在需要发布前不要急于merge到主干，而是将少许的修改先发布在www.inyour.facebook.com。&lt;/p&gt;

&lt;p&gt;Facebook.com主站也不能用作沙盒， 开发人员是不允许在生产环境随意测试的。如果你有10亿用户，就千万别事情在生产环境搞砸了。在Facebook有一套完全分离的并且具有较好鲁棒性的沙盒。&lt;/p&gt;

&lt;p&gt;Facebook确保了整个系统中的每一块都有工程师负责，并且有一个快速找到On-call人员的工具。在Facebook On-call职责非常严肃认真，没有工程师可以逃离于On-call职责之外。&lt;/p&gt;

&lt;h2 id='facebook'&gt;Facebook的工具&lt;/h2&gt;

&lt;h3 id='id174'&gt;自服务&lt;/h3&gt;

&lt;p&gt;在Facebook 你可以在IRC中做任何事情，IRC一个频道有上千人规模。简单的问题由机器人回答，比如查询任何一个待发布版本的状态的，同样也有浏览器截图。 机器人是你的朋友，像一只宠物狗一样跟随你，也有机器人会问开发人员去确认是否想把代码修改做发布。&lt;/p&gt;

&lt;h3 id='id175'&gt;知道我们在哪儿？&lt;/h3&gt;

&lt;p&gt;Facebook 有一个显示每天发布状态的仪表盘，还有一个测试控制台。当Chuck进行最后merge的时候，会立即发起系统测试，他们大概有3500个单元测试用例并且在每台机器上运行。每次大的改变都会进行这些测试。&lt;/p&gt;

&lt;h3 id='error_tracking_'&gt;Error tracking &lt;font color='blue'&gt; [亮点]&lt;/font&gt;&lt;/h3&gt;

&lt;p&gt;Facebook有成千上万的web服务器，错误日志中饱含有用数据但他们不得不为大量级的日志专门编写了一个日志聚合器。在Facebook你可以通过仪表盘，点击一处日志错误然后查看对应的调用栈，点开一个函数就会展开代码对应的git blame信息，从而告诉你这段错误是谁引入的。Chuck他们还用一个名为Scuba的分析系统，这个系统可以展示其他事件的关系及对应趋势，比如用鼠标滑过某错误时，你就可以得到这个错误最近的出现趋势图。&lt;/p&gt;

&lt;h3 id='gatekeeper'&gt;Gatekeeper&lt;/h3&gt;

&lt;p&gt;这是Facebook主要的战略优势之一，即打开环境的钥匙。这是一个由终端控制的feature flag（译注：类似于gflags，用标志开关控制feature）管理者，你可以有选择的打开新的feature，防止某些群组的用户察觉到刚做的变更。一次他们作为玩笑为Techcrunch打开了“传真你的照片”的feature开关。&lt;/p&gt;

&lt;h3 id='push_karma_'&gt;Push karma &lt;font color='blue'&gt; [亮点]&lt;/font&gt;&lt;/h3&gt;

&lt;p&gt;Chuck的工作就是管理风险。他观察仪表盘显示的这次变更的大小、diff工具中的讨论数量（通常只这次修改的冲突大小），如果发现这两个指标都很高，他就会更仔细查看了。 他也可以看到每个变更请求者的发布karma高达5颗星。他有一个unlike按钮去降低你的karma，要知道如果你的karma降到两星，Chuck就会停止发布的你的改进，你就不得不过来与他谈谈如何提升你的发布能力，让你的发布重新回到正规。&lt;/p&gt;

&lt;h3 id='perflab'&gt;Perflab&lt;/h3&gt;

&lt;p&gt;这是一个用来做性能回归的强大工具，它可以比较主干和最新发布版本的性能。&lt;/p&gt;

&lt;h3 id='hiphop_for_php'&gt;HipHop for PHP&lt;/h3&gt;

&lt;p&gt;这是一个由600个高度优化后的C++文件编译而成的二进制工具， 但是有些时候他们也在开发环境中使用解释性的PHP，他们计划用准备开源的PHP虚拟机来解决这个问题。&lt;/p&gt;

&lt;h3 id='bittorrent_'&gt;Bittorrent &lt;font color='blue'&gt; [亮点]&lt;/font&gt;&lt;/h3&gt;

&lt;p&gt;这是他们分发大量二进制文件到成千上万台机器使用的peer-to-peer工具。bt的客户端向Open Tracker服务器请求节点，这样强大的分发能力可以保证数据15分钟内分发完成。&lt;/p&gt;

&lt;h2 id='id176'&gt;仅仅依靠工具是不能拯救你的&lt;/h2&gt;

&lt;p&gt;最后，最重要的一点是，你不能依靠工具去改变你的状态。海外那些被洗过脑的人往往只吸收到了文化的部分，孰不知你需要的是一个公司的支持，从头到尾的支持。&lt;/p&gt;

&lt;h2 id='id177'&gt;引申阅读：&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;在Facebook程序的发布安排在哪天是有规定的，有规律的。&lt;/li&gt;

&lt;li&gt;karmar，梵文指业力；业力是指个人过去、现在或将来的行为所引发的结果的集合。&lt;/li&gt;
&lt;/ol&gt;</content>
 </entry>
 
 <entry>
   <title>[全文转载]How complex systems fail</title>
   <link href="http://www.baidu-ops.com/2012/09/20/how-complex-systems-fail"/>
   <updated>2012-09-20T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/09/20/how-complex-systems-fail</id>
   <content type="html">&lt;p&gt;&lt;a href='http://blog.liancheng.info/how-complex-systems-fail-zh/'&gt;本文转载自-连城&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href='http://www.ctlab.org/documents/How%20Complex%20Systems%20Fail.pdf'&gt;英文原文&lt;/a&gt;&lt;/p&gt;

&lt;h2 id='id155'&gt;复杂系统本质上都是高风险系统&lt;/h2&gt;

&lt;p&gt;各种备受瞩目的复杂系统（如交通系统、医疗系统、电力系统等）都是高风险系统，这是它们固有的内在属性。尽管风险事故的爆发频度时有高低，导致系统固有高风险性的内因却无从化解。这些风险又催生了各式各样的风险防范措施，进而塑造了形形色色的复杂系统。&lt;/p&gt;

&lt;h2 id='id156'&gt;复杂系统都对故障严加防范并且行之有效&lt;/h2&gt;

&lt;p&gt;故障造成的高昂代价促使人们逐渐构筑起重重防范措施来抵御故障。其中既包括必要的技术措施（如后备系统、设备的各种“安全”功能等）和人力措施（如培训、经验传承等），也包括多种机构性措施、制度性措施和监管性措施（如政策流程、资格认证、工作守则、团队培训等）。这些手段构成了一系列防护，令日常运维得以远离意外事故。&lt;/p&gt;

&lt;h2 id='id157'&gt;灾难性事故是由多起故障共同造成的——单点故障不足以兴风作浪&lt;/h2&gt;

&lt;p&gt;多重防范的确行之有效，一般情况下足以保障系统正常运转。重大灾难性事故往往是由多起无足轻重的轻微故障共同导致的系统性的意外事故。这些轻微故障中的每一起都是事故的诱因，但只有当它们叠加在一起时，才会酿成事故。换言之，故障的发生概率比重大系统事故的发生概率要高得多。系统内预设的安全组件可以排除大部分故障。渗入到业务层面的故障绝大部分也会被排除，这一层面的故障通常需要从业人员人工处理。&lt;/p&gt;

&lt;h2 id='id158'&gt;复杂系统中潜伏着变化多端的故障组合&lt;/h2&gt;

&lt;p&gt;由于复杂性过高，这些系统在运转时总是伴随着多种缺陷。然而这些缺陷在系统运转过程中显得无足轻重，因为其中的任何一种缺陷都不足以单方面导致故障。要彻底清除潜在故障，经济成本往往太过高昂。此外，除非真的发生事故，否则我们也很难看出这些故障如何会诱发事故。不断演变的技术和工作机构，再加上人们为了排除故障而付出的种种努力，使得故障也不断地发生变化。&lt;/p&gt;

&lt;h2 id='id159'&gt;复杂系统运转时总是处于降级模式&lt;/h2&gt;

&lt;p&gt;由上一条可知，运转中的复杂系统总是残缺不全。之所以还能运转，是因为系统内备有充足的冗余部件，即便存在诸多缺陷，人们仍然有办法让它工作。从以往的事故评估结果来看，事发之前系统几乎都出现过险些酿成灾难的“准事故（proto-accident）”。有观点认为，通常情况下，简单的系统性能监控手段便足以发现这些系统降级情况，它们本该在重大事故发生之前就得到应有的重视。系统的运作过程是动态的，各种（机构、人员、技术）部件会不断发生故障进而被更替。&lt;/p&gt;

&lt;h2 id='id160'&gt;灾难总是近在咫尺&lt;/h2&gt;

&lt;p&gt;复杂系统都有可能引发灾难性故障。在从业人员的身边，各种潜在故障每时每刻如影随行——灾难随时随地都有可能发生。所有复杂系统都有可能导致灾难性的后果，这是它们的标志性特征之一。人们不可能完全杜绝这类灾难性故障；这是由系统自身的性质决定的。&lt;/p&gt;

&lt;h2 id='id161'&gt;在事发之后将事故归咎于某一“罪魁祸首”的做法是完全不可取的&lt;/h2&gt;

&lt;p&gt;重大故障都是由多重失误共同造成的，因此事故背后的“肇因”不可能是孤立的。导致事故的因素多种多样，但其中任何一种都不足以单方面造成事故。只有当这些因素叠加在一起时事故才会发生。实际上，滋生事故的温床正是由这些因素环环相扣共同形成的。因此，事故背后根本就不存在孤立的“罪魁祸首”。这种将事故归咎于某一“罪魁祸首”的做法无法反映故障的技术本质；之所以抓住某一局部力量或事件不放并加以责难，无非为了迎合社会和文化诉求罢了。&lt;/p&gt;

&lt;h2 id='id162'&gt;事后成见会扭曲事故评定人员的认知&lt;/h2&gt;

&lt;p&gt;在已知事故后果的情况下，人们会产生一种错觉，倾向于认为当事人理应更早注意到酿成事故的种种事件。这意味着人们无法客观地分析事故经过。已然了解事故后果的事故分析人员往往会先入为主，难以站在当事人的角度忠实地还原事故经过。当事人似乎“理应注意到”这些因素“必将”导致事故。事后成见一直是事故调查中的主要障碍，尤其是在有专家参与的时候。&lt;/p&gt;

&lt;h2 id='id163'&gt;操作人员分饰二角：他们既是故障的始作俑者，也是故障的防范者&lt;/h2&gt;

&lt;p&gt;系统内的从业人员一边操纵系统从事生产，一边防范事故的发生。系统运转过程中的这一动态特质，以及业务需求与故障滋生风险之间的矛盾是不可避免的。外界很少有人能够认识到这一角色的二重性。系统正常运转时，唱主角的是生产角色；事故发生后，主角则换成了故障防范角色。实际上，系统操作人员一直长期且持续地分饰二角，这一点往往为外界所误解。&lt;/p&gt;

&lt;h2 id='id164'&gt;当事人的举动完全是在冒险&lt;/h2&gt;

&lt;p&gt;事故发生之后，人们往往会认为早在事发之前导致事故的重大故障就已经在所难免，之所以最终会酿成事故，是因为当事人在故障迫近时处理失当或玩忽职守。但实际上，当事人在采取行动时完全是在冒险，他们无法预知自己的行动会导致什么后果。其中的不确定性在程度上时有不同。当事人的冒险行为在事故之后体现得尤为明显；灾后分析通常都不会将这些行为判作明智之举。反过来看：即便处理得当，也不过是瞎猫碰上死老鼠，无法得到广泛认同。&lt;/p&gt;

&lt;h2 id='id165'&gt;风口浪尖上的行为令一切模糊性消失殆尽&lt;/h2&gt;

&lt;p&gt;各种组织机构都存在一定的模糊性，而且这种模糊性往往是蓄意造成的，它体现在生产目标、资源使用效率、运作成本，以及对不同程度的潜在事故的容忍度等多个方面。然而在评判那些被抛至风口浪尖的从业人员的行为时，这些模糊性却消失殆尽。发生事故之后，当事人的行为往往会被视为“失误”或“违规”，但这类评判带有严重的事后成见，往往无视业绩压力等其他诱因。&lt;/p&gt;

&lt;h2 id='id166'&gt;从业人员会对复杂系统进行调整&lt;/h2&gt;

&lt;p&gt;从业人员及一线管理者会积极调整系统，一边扩大产值一边减少事故。这种调整每时每刻都在进行，包括：（1）系统重组，避免脆弱部件遭受故障。（2）集中稀缺资源，应对关键需求。（3）留出后路，用以躲避或修复各种可预期及不可预期的故障。（4）针对系统性能的变化建立各种早期检测手段以妥善紧缩生产规模，或通过其他手段提高系统的恢复能力。&lt;/p&gt;

&lt;h2 id='id167'&gt;复杂系统中的专业人才不断更替&lt;/h2&gt;

&lt;p&gt;运作和管理复杂系统需要大量专业人才。迫于技术革新的压力，同时也为了填补人才流动所致的空缺，从业人员的专业知识必须不断更新。无论出于什么目的，技能和专业知识的培训和锻炼都应该成为系统自身的职能之一。由此可见，复杂系统中时刻存在着身怀不同程度的专业知识的从业人员和受训人员。有关专业知识的关键问题主要表现在（1）对能够胜任最困难、最艰巨的生产任务的稀缺专业人才资源的需求，以及（2）为了应对未来需求而进行的技术储备。&lt;/p&gt;

&lt;h2 id='id168'&gt;变化会引入新的故障&lt;/h2&gt;

&lt;p&gt;在可靠性较高的系统中，重大事故的发生频率较低，这使得人们更乐于接受变化，尤其是以减少影响较小的频发性故障为目的引入新技术。然而这些变化有可能会引入新的、后果严重的偶发性故障。在应用新技术清除已知的系统故障或追求更高的性能的同时，往往会埋下可能引发新的大规模灾难性故障的隐患。不少情况下，比起采用新技术清除掉的那些故障，这些新的、罕见的灾难性事故所造成的影响甚至更加恶劣。事发之前很难发现这些新型故障；人们的注意力大都集中到设想中的借由变化带来的收益上去了。由于这类新的恶性事故发生的频率很低，事发之前系统可能已经经历过多次变更，加大了识别事故的技术原因的难度。&lt;/p&gt;

&lt;h2 id='id169'&gt;抵御未来事件的效果受限于人们看待“肇因”的方式&lt;/h2&gt;

&lt;p&gt;发生事故之后，为了防范事故中的“人为失误”，人们通常会想方设法阻断各种可能“导致”事故的事件。这种做法治标不治本，在事故防范方面起到的作用十分有限。实际上，由于潜在故障的模式不断地发生变化，相同事故重复发生的概率非常低。这类事后防范措施往往难以起到增强安全性的作用，反而还会加重系统的耦合性和复杂性。这么做不仅会催生更多潜在故障，而且还会加剧事故的排查难度。&lt;/p&gt;

&lt;h2 id='id170'&gt;安全性是系统整体的特性，而不是系统中各部件的特性&lt;/h2&gt;

&lt;p&gt;安全性是系统的自发属性；它不是独立的个人、设备、组织中的某个部门或系统所能决定的。安全性无法通过购买或生产途径获取；它无法脱离系统中的其他组件而独立存在。因此人们无法像加工原材料那样加工安全性。无论何时，安全性在任何系统中都是动态的；系统自身持续不断的变化必然导致灾难性故障及其应对方式发生相应的变化。&lt;/p&gt;

&lt;h2 id='id171'&gt;人们持续不断地营造安全的环境&lt;/h2&gt;

&lt;p&gt;无故障运营的背后凝结着人们付出的种种努力，他们想方设法将系统的性能波动控制在可承受范围内。这些努力中的一大部分原本就是日常运维工作的一部分，相当直截了当。然而系统的运转过程从来都不是一帆风顺的，迫于周遭条件的变化，从业人员必须及时采取措施，不断营造安全的环境。这些措施通常都出自一组经过充分演练的对策集；但有时也会出现新颖的策略组合或完全创新的解决方案。&lt;/p&gt;

&lt;h2 id='id172'&gt;无故障运营需要故障处理相关的经验&lt;/h2&gt;

&lt;p&gt;只有真刀真枪地处理过故障的人才能识别出灾难性故障，并成功地将系统的性能波动维系在可承受范围之内。如果运维人员充分重视系统的极限情况，系统的表现往往就会更加稳定。一旦被逼入极限情况，系统的表现便开始恶化，变得捉摸不定，或是难以恢复稳定。对于具有内在高风险性的系统，运维人员应当以把控系统整体运作情况为主，正确认识到事故的必然性并予以重视。安全性的提升离不开对意外事故有正确认识的运维人员；同时，运维人员也必须清楚地认识到自己采取的措施会如何影响系统，如何令系统逼近或远离极限情况。&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>[全文转载]Google Spanner原理- 全球级的分布式数据库</title>
   <link href="http://www.baidu-ops.com/2012/09/20/google-spanner"/>
   <updated>2012-09-20T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/09/20/google-spanner</id>
   <content type="html">&lt;p&gt;&lt;a href='http://qing.weibo.com/2294942122/88ca09aa3300221n.html'&gt;本文转载自EMC研究员-颜开&lt;/a&gt;&lt;/p&gt;

&lt;h2 id='google_spanner'&gt;Google Spanner简介&lt;/h2&gt;

&lt;p&gt;Spanner 是Google的全球级的分布式数据库 (Globally-Distributed Database)。Spanner的扩展性达到了令人咋舌的全球级，可以扩展到数百万的机器，数已百计的数据中心，上万亿的行。更给力的是，除了夸张的扩展性之外，他还能同时通过同步复制和多版本来满足外部一致性，可用性也是很好的。冲破CAP的枷锁，在三者之间完美平衡。&lt;/p&gt;

&lt;p&gt;&lt;img alt='design-goals-for-spanner' src='/assets/themes/twitter/bootstrap/img/2012-09-20-google-spanner/design-goals-for-spanner.jpg' /&gt;&lt;/p&gt;

&lt;p&gt;Spanner是个可扩展，多版本，全球分布式还支持同步复制的数据库。他是Google的第一个可以全球扩展并且支持外部一致的事务。Spanner能做到这些，离不开一个用GPS和原子钟实现的时间API。这个API能将数据中心之间的时间同步精确到10ms以内。因此有几个给力的功能：无锁读事务，原子schema修改，读历史数据无block。 EMC中国研究院实时紧盯业界动态，Google最近发布的一篇论文《&lt;a href='http://research.google.com/archive/spanner.html'&gt;Spanner:Google&amp;#8217;s Globally-Distributed Database&lt;/a&gt;》,笔者非常感兴趣，对Spanner进行了一些调研，并在这里分享。由于Spanner并不是开源产品，笔者的知识主要来源于Google的公开资料，通过现有公开资料仅仅只能窥得Spanner的沧海一粟，Spanner背后还依赖有大量Google的专有技术。 下文主要是Spanner的背景，设计和并发控制。&lt;/p&gt;

&lt;h2 id='spanner'&gt;Spanner背景&lt;/h2&gt;

&lt;p&gt;要搞清楚Spanner原理，先得了解Spanner在Google的定位。&lt;/p&gt;

&lt;p&gt;&lt;img alt='F1' src='/assets/themes/twitter/bootstrap/img/2012-09-20-google-spanner/F1.jpg' /&gt;&lt;/p&gt;

&lt;p&gt;从上图可以看到。Spanner位于F1和GFS之间，承上启下。所以先提一提F1和GFS。&lt;/p&gt;

&lt;h2 id='f1'&gt;F1&lt;/h2&gt;

&lt;p&gt;和众多互联网公司一样，在早期Google大量使用了Mysql。Mysql是单机的，可以用Master-Slave来容错，分区来扩展。但是需要大量的手工运维工作，有很多的限制。因此Google开发了一个可容错可扩展的RDBMS——F1。和一般的分布式数据库不同，F1对应RDMS应有的功能，毫不妥协。起初F1是基于Mysql的，不过会逐渐迁移到Spanner。 F1有如下特点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* 7×24高可用(哪怕某一个数据中心停止运转 仍然可用)
* 可扩展
* 支持SQL
* 事务提交延迟50-100ms 读延迟5-10ms 高吞吐
* 可以同时提供强一致性和弱一致&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;众所周知Google BigTable是重要的NoSql产品，提供很好的扩展性，开源世界有HBase与之对应。为什么Google还需要F1，而不是都使用BigTable呢？因为BigTable提供的最终一致性，一些需要事务级别的应用无法使用。同时BigTable还是NoSql，而大量的应用场景需要有关系模型。就像现在大量的互联网企业都使用Mysql而不愿意使用HBase，因此Google才有这个可扩展数据库的F1。而Spanner就是F1的至关重要的底层存储技术。&lt;/p&gt;

&lt;h2 id='colossusgfs_ii'&gt;Colossus（GFS II）&lt;/h2&gt;

&lt;p&gt;Colossus也是一个不得不提起的技术。他是第二代GFS，对应开源世界的新HDFS。GFS是著名的分布式文件系统。&lt;/p&gt;

&lt;p&gt;&lt;img alt='GFS-Architecture' src='/assets/themes/twitter/bootstrap/img/2012-09-20-google-spanner/GFS-Architecture.jpg' /&gt;&lt;/p&gt;

&lt;p&gt;初代GFS是为批处理设计的。对于大文件很友好，吞吐量很大，但是延迟较高。所以使用他的系统不得不对GFS做各种优化，才能获得良好的性能。那为什么Google没有考虑到这些问题，设计出更完美的GFS?因为那个时候是2001年，Hadoop出生是在2007年。如果Hadoop是世界领先水平的话，GFS比世界领先水平还领先了6年。同样的Spanner出生大概是2009年，现在我们看到了论文，估计Spanner在Google已经很完善，同时Google内部已经有更先进的替代技术在酝酿了。笔者预测，最早在2015年才会出现Spanner和F1的山寨开源产品。 Colossus是第二代GFS。Colossus是Google重要的基础设施，因为他可以满足主流应用对FS的要求。Colossus的重要改进有：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* 优雅Master容错处理 (不再有2s的停止服务时间)
* Chunk大小只有1MB (对小文件很友好)
* Master可以存储更多的Metadata(当Chunk从64MB变为1MB后，Metadata会扩大64倍，但是Google也解决了)&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Colossus可以自动分区Metadata。使用Reed-Solomon算法来复制，可以将原先的3份减小到1.5份，提高写的性能，降低延迟。客户端来复制数据。具体细节笔者也猜不出。&lt;/p&gt;

&lt;h2 id='bigtable_megastore'&gt;与BigTable， Megastore对比&lt;/h2&gt;

&lt;p&gt;Spanner主要致力于跨数据中心的数据复制上，同时也能提供数据库功能。在Google类似的系统有BigTable和Megastore。和这两者相比，Spanner又有什么优势呢。&lt;/p&gt;

&lt;p&gt;BigTable在Google得到了广泛的使用，但是他不能提供较为复杂的Schema，还有在跨数据中心环境下的强一致性。Megastore有类RDBMS的数据模型，同时也支持同步复制，但是他的吞吐量太差，不能适应应用要求。Spanner不再是类似BigTable的版本化key-value存储，而是一个“临时多版本”的数据库。何为“临时多版本”，数据是存储在一个版本化的关系表里面，存储的时间数据会根据其提交的时间打上时间戳，应用可以访问到较老的版本，另外老的版本也会被垃圾回收掉。&lt;/p&gt;

&lt;p&gt;Google官方认为 Spanner是下一代BigTable，也是Megastore的继任者。&lt;/p&gt;

&lt;h2 id='google_spanner'&gt;Google Spanner设计&lt;/h2&gt;

&lt;h3 id='id149'&gt;功能&lt;/h3&gt;

&lt;p&gt;从高层看Spanner是通过Paxos状态机将分区好的数据分布在全球的。数据复制全球化的，用户可以指定数据复制的份数和存储的地点。Spanner可以在集群或者数据发生变化的时候将数据迁移到合适的地点，做负载均衡。用户可以指定将数据分布在多个数据中心，不过更多的数据中心将造成更多的延迟。用户需要在可靠性和延迟之间做权衡，一般来说复制1，2个数据中心足以保证可靠性。 作为一个全球化分布式系统，Spanner提供一些有趣的特性。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* 应用可以细粒度的指定数据分布的位置。精确的指定数据离用户有多远，可以有效的控制读延迟(读延迟取决于最近的拷贝)。指定数据拷贝之间有多远，可以控制写的延迟(写延迟取决于最远的拷贝)。还要数据的复制份数，可以控制数据的可靠性和读性能。(多写几份，可以抵御更大的事故)
* Spanner还有两个一般分布式数据库不具备的特性：读写的外部一致性，基于时间戳的全局的读一致。这两个特性可以让Spanner支持一致的备份，一致的MapReduce，还有原子的Schema修改。&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这写特性都得益有Spanner有一个全球时间同步机制，可以在数据提交的时候给出一个时间戳。因为时间是系列化的，所以才有外部一致性。这个很容易理解，如果有两个提交，一个在T1,一个在T2。那有更晚的时间戳那个提交是正确的。&lt;/p&gt;

&lt;p&gt;这个全球时间同步机制是用一个具有GPS和原子钟的TrueTime API提供了。这个TrueTime API能够将不同数据中心的时间偏差缩短在10ms内。这个API可以提供一个精确的时间，同时给出误差范围。Google已经有了一个TrueTime API的实现。笔者觉得这个TrueTime API非常有意义，如果能单独开源这部分的话，很多数据库如MongoDB都可以从中受益。&lt;/p&gt;

&lt;h3 id='id150'&gt;体系结构&lt;/h3&gt;

&lt;p&gt;Spanner由于是全球化的，所以有两个其他分布式数据库没有的概念。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* Universe。一个Spanner部署实例称之为一个Universe。目前全世界有3个。一个开发，一个测试，一个线上。因为一个Universe就能覆盖全球，不需要多个。
* Zones.每个Zone相当于一个数据中心，一个Zone内部物理上必须在一起。而一个数据中心可能有多个Zone。可以在运行时添加移除Zone。一个Zone可以理解为一个BigTable部署实例。&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img alt='spanner-server-organization' src='/assets/themes/twitter/bootstrap/img/2012-09-20-google-spanner/spanner-server-organization.jpg' /&gt;&lt;/p&gt;

&lt;p&gt;如图所示。一个Spanner有上面一些组件。实际的组件肯定不止这些，比如TrueTime API Server。如果仅仅知道这些知识，来构建Spanner是远远不够的。但Google都略去了。那笔者就简要介绍一下。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* Universemaster: 监控这个universe里zone级别的状态信息
* Placement driver：提供跨区数据迁移时管理功能
* Zonemaster：相当于BigTable的Master。管理Spanserver上的数据。
* Location proxy：存储数据的Location信息。客户端要先访问他才知道数据在那个Spanserver上。
* Spanserver：相当于BigTable的ThunkServer。用于存储数据。&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出来这里每个组件都很有料，但是Google的论文里只具体介绍了Spanserver的设计，笔者也只能介绍到这里。下面详细阐述Spanserver的设计。&lt;/p&gt;

&lt;h3 id='spanserver'&gt;Spanserver&lt;/h3&gt;

&lt;p&gt;本章详细介绍Spanserver的设计实现。Spanserver的设计和BigTable非常的相似。参照下图&lt;/p&gt;

&lt;p&gt;&lt;img alt='spanserver-software-stack' src='/assets/themes/twitter/bootstrap/img/2012-09-20-google-spanner/spanserver-software-stack.jpg' /&gt;&lt;/p&gt;

&lt;p&gt;从下往上看。每个数据中心会运行一套Colossus (GFS II)。每个机器有100-1000个tablet。Tablet概念上将相当于数据库一张表里的一些行，物理上是数据文件。打个比方，一张1000行的表，有10个tablet，第1-100行是一个tablet，第101-200是一个tablet。但和BigTable不同的是BigTable里面的tablet存储的是Key-Value都是string，Spanner存储的Key多了一个时间戳：&lt;/p&gt;

&lt;p&gt;(Key: string, timestamp: int64) -&amp;gt;string。&lt;/p&gt;

&lt;p&gt;因此spanner天生就支持多版本，tablet在文件系统中是一个B-tree-like的文件和一个write-ahead日志。 每个Tablet上会有一个Paxos状态机。Paxos是一个分布式一致性协议。Table的元数据和log都存储在上面。Paxos会选出一个replica做leader，这个leader的寿命默认是10s,10s后重选。Leader就相当于复制数据的master，其他replica的数据都是从他那里复制的。读请求可以走任意的replica，但是写请求只有去leader。这些replica统称为一个paxos group。&lt;/p&gt;

&lt;p&gt;每个leader replica的spanserver上会实现一个lock table还管理并发。Lock table记录了两阶段提交需要的锁信息。但是不论是在Spanner还是在BigTable上，但遇到冲突的时候长时间事务会将性能很差。所以有一些操作，如事务读可以走lock table，其他的操作可以绕开lock table。&lt;/p&gt;

&lt;p&gt;每个leader replica的spanserver上还有一个transaction manager。如果事务在一个paxos group里面，可以绕过transaction manager。但是一旦事务跨多个paxos group，就需要transaction manager来协调。其中一个Transactionmanager被选为leader，其他的是slave听他指挥。这样可以保证事务。&lt;/p&gt;

&lt;h3 id='directories_and_placement'&gt;Directories and Placement&lt;/h3&gt;

&lt;p&gt;之所以Spanner比BigTable有更强的扩展性，在于Spanner还有一层抽象的概念directory, directory是一些key-value的集合，一个directory里面的key有一样的前缀。更妥当的叫法是bucketing。Directory是应用控制数据位置的最小单元，可以通过谨慎的选择Key的前缀来控制。据此笔者可以猜出，在设计初期，Spanner是作为F1的存储系统而设立，甚至还设计有类似directory的层次结构，这样的层次有很多好处，但是实现太复杂被摒弃了。&lt;/p&gt;

&lt;p&gt;Directory作为数据放置的最小单元，可以在paxos group里面移来移去。Spanner移动一个directory一般出于如下几个原因：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* 一个paxos group的负载太大，需要切分
* 将数据移动到access更近的地方
* 经常同时访问的directory放到一个paxos group里面&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Directory可以在不影响client的前提下，在后台移动。移动一个50MB的directory大概需要的几秒钟。那么directory和tablet又是什么关系呢。可以理解为Directory是一个抽象的概念，管理数据的单元；而tablet是物理的东西，数据文件。由于一个Paxos group可能会有多个directory，所以spanner的tablet实现和BigTable的tablet实现有些不同。BigTable的tablet是单个顺序文件。Google有个项目，名为Level DB，是BigTable的底层，可以看到其实现细节。而Spanner的tablet可以理解是一些基于行的分区的容器。这样就可以将一些经常同时访问的directory放在一个tablet里面，而不用太在意顺序关系。&lt;/p&gt;

&lt;p&gt;在paxos group之间移动directory是后台任务。这个操作还被用来移动replicas。移动操作设计的时候不是事务的，因为这样会造成大量的读写block。操作的时候是先将实际数据移动到指定位置，然后再用一个原子的操作更新元数据，完成整个移动过程。&lt;/p&gt;

&lt;p&gt;Directory还是记录地理位置的最小单元。数据的地理位置是由应用决定的，配置的时候需要指定复制数目和类型，还有地理的位置。比如(上海，复制2份；南京复制1分)。这样应用就可以根据用户指定终端用户实际情况决定的数据存储位置。比如中国队的数据在亚洲有3份拷贝,日本队的数据全球都有拷贝。&lt;/p&gt;

&lt;p&gt;前面对directory还是被简化过的，还有很多无法详述。&lt;/p&gt;

&lt;h3 id='id151'&gt;数据模型&lt;/h3&gt;

&lt;p&gt;Spanner的数据模型来自于Google内部的实践。在设计之初，Spanner就决心有以下的特性：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* 支持类似关系数据库的schema
* Query语句
* 支持广义上的事务&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为何会这样决定呢？在Google内部还有一个Megastore，尽管要忍受性能不够的折磨，但是在Google有300多个应用在用它，因为Megastore支持一个类似关系数据库的schema，而且支持同步复制(BigTable只支持最终一致的复制) 。使用Megastore的应用有大名鼎鼎的Gmail,Picasa, Calendar, Android Market和AppEngine。而必须对Query语句的支持，来自于广受欢迎的Dremel，笔者不久前写了篇文章来介绍他。最后对事务的支持是比不可少了，BigTable在Google内部被抱怨的最多的就是其只能支持行事务，再大粒度的事务就无能为力了。Spanner的开发者认为，过度使用事务造成的性能下降的恶果，应该由应用的开发者承担。应用开发者在使用事务的时候，必须考虑到性能问题。而数据库必须提供事务机制，而不是因为性能问题，就干脆不提供事务支持。&lt;/p&gt;

&lt;p&gt;数据模型是建立在directory和key-value模型的抽象之上的。一个应用可以在一个universe中建立一个或多个database，在每个database中建立任意的table。Table看起来就像关系型数据库的表。有行，有列，还有版本。Query语句看起来是多了一些扩展的SQL语句。&lt;/p&gt;

&lt;p&gt;Spanner的数据模型也不是纯正的关系模型，每一行都必须有一列或多列组件。看起来还是Key-value。主键组成Key,其他的列是Value。但这样的设计对应用也是很有裨益的，应用可以通过主键来定位到某一行。&lt;/p&gt;

&lt;p&gt;&lt;img alt='data-model' src='/assets/themes/twitter/bootstrap/img/2012-09-20-google-spanner/datamodel.jpg' /&gt;&lt;/p&gt;

&lt;p&gt;上图是一个例子。对于一个典型的相册应用，需要存储其用户和相册。可以用上面的两个SQL来创建表。Spanner的表是层次化的，最顶层的表是directory table。其他的表创建的时候，可以用interleave in parent来什么层次关系。这样的结构，在实现的时候，Spanner可以将嵌套的数据放在一起，这样在分区的时候性能会提升很多。否则Spanner无法获知最重要的表之间的关系。&lt;/p&gt;

&lt;h3 id='truetime'&gt;TrueTime&lt;/h3&gt;

&lt;p&gt;&lt;img alt='truetime' src='/assets/themes/twitter/bootstrap/img/2012-09-20-google-spanner/truetime.jpg' /&gt;&lt;/p&gt;

&lt;p&gt;TrueTime API 是一个非常有创意的东西，可以同步全球的时间。上表就是TrueTime API。TT.now()可以获得一个绝对时间TTinterval，这个值和UnixTime是相同的，同时还能够得到一个误差e。TT.after(t)和TT.before(t)是基于TT.now()实现的。&lt;/p&gt;

&lt;p&gt;那这个TrueTime API实现靠的是GFS和原子钟。之所以要用两种技术来处理，是因为导致这两个技术的失败的原因是不同的。GPS会有一个天线，电波干扰会导致其失灵。原子钟很稳定。当GPS失灵的时候，原子钟仍然能保证在相当长的时间内，不会出现偏差。&lt;/p&gt;

&lt;p&gt;实际部署的时候。每个数据中心需要部署一些Master机器，其他机器上需要有一个slave进程来从Master同步。有的Master用GPS，有的Master用原子钟。这些Master物理上分布的比较远，怕出现物理上的干扰。比如如果放在一个机架上，机架被人碰倒了，就全宕了。另外原子钟不是并很贵。Master自己还会不断比对，新的时间信息还会和Master自身时钟的比对，会排除掉偏差比较大的，并获得一个保守的结果。最终GPS master提供时间精确度很高，误差接近于0。&lt;/p&gt;

&lt;p&gt;每个Slave后台进程会每个30秒从若干个Master更新自己的时钟。为了降低误差，使用Marzullo算法。每个slave还会计算出自己的误差。这里的误差包括的通信的延迟，机器的负载。如果不能访问Master，误差就会越走越大，知道重新可以访问。&lt;/p&gt;

&lt;h3 id='google_spanner'&gt;Google Spanner并发控制&lt;/h3&gt;

&lt;p&gt;Spanner使用TrueTime来控制并发，实现外部一致性。支持以下几种事务。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* 读写事务
* 只读事务
* 快照读，客户端提供时间戳
* 快照读，客户端提供时间范围&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例如一个读写事务发生在时间t，那么在全世界任何一个地方，指定t快照读都可以读到写入的值。&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Operation&lt;/th&gt;&lt;th&gt;Concurrency Control&lt;/th&gt;&lt;th&gt;Replica Required&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;Read-Write Transaction&lt;/td&gt;&lt;td style='text-align: left;'&gt;pessimistic&lt;/td&gt;&lt;td style='text-align: left;'&gt;leader&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;Read-Only Transaction&lt;/td&gt;&lt;td style='text-align: left;'&gt;lock-free&lt;/td&gt;&lt;td style='text-align: left;'&gt;leader for timestamp;any for read&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;Snapshot Read,client-provided&lt;/td&gt;&lt;td style='text-align: left;'&gt;lock-free&lt;/td&gt;&lt;td style='text-align: left;'&gt;any&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;Snapshot Read,client-provided bound&lt;/td&gt;&lt;td style='text-align: left;'&gt;lock-free&lt;/td&gt;&lt;td style='text-align: left;'&gt;any&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;上表是Spanner现在支持的事务。单独的写操作都被实现为读写事务 ；单独的非快照被实现为只读事务。事务总有失败的时候，如果失败，对于这两种操作会自己重试，无需应用自己实现重试循环。&lt;/p&gt;

&lt;p&gt;时间戳的设计大大提高了只读事务的性能。事务开始的时候，要声明这个事务里没有写操作，只读事务可不是一个简单的没有写操作的读写事务。它会用一个系统时间戳去读，所以对于同时的其他的写操作是没有Block的。而且只读事务可以在任意一台已经更新过的replica上面读。&lt;/p&gt;

&lt;p&gt;对于快照读操作，可以读取以前的数据，需要客户端指定一个时间戳或者一个时间范围。Spanner会找到一个已经充分更新好的replica上读取。&lt;/p&gt;

&lt;p&gt;还有一个有趣的特性的是，对于只读事务，如果执行到一半，该replica出现了错误。客户端没有必要在本地缓存刚刚读过的时间，因为是根据时间戳读取的。只要再用刚刚的时间戳读取，就可以获得一样的结果。&lt;/p&gt;

&lt;h3 id='id152'&gt;读写事务&lt;/h3&gt;

&lt;p&gt;正如BigTable一样，Spanner的事务是会将所有的写操作先缓存起来，在Commit的时候一次提交。这样的话，就读不出在同一个事务中写的数据了。不过这没有关系，因为Spanner的数据都是有版本的。&lt;/p&gt;

&lt;p&gt;在读写事务中使用wound-wait算法来避免死锁。当客户端发起一个读写事务的时候，首先是读操作，他先找到相关数据的leader replica，然后加上读锁，读取最近的数据。在客户端事务存活的时候会不断的向leader发心跳，防止超时。当客户端完成了所有的读操作，并且缓存了所有的写操作，就开始了两阶段提交。客户端闲置一个coordinator group，并给每一个leader发送coordinator的id和缓存的写数据。&lt;/p&gt;

&lt;p&gt;leader首先会上一个写锁，他要找一个比现有事务晚的时间戳。通过Paxos记录。每一个相关的都要给coordinator发送他自己准备的那个时间戳。&lt;/p&gt;

&lt;p&gt;Coordinatorleader一开始也会上个写锁，当大家发送时间戳给他之后，他就选择一个提交时间戳。这个提交的时间戳，必须比刚刚的所有时间戳晚，而且还要比TT.now()+误差时间 还有晚。这个Coordinator将这个信息记录到Paxos。&lt;/p&gt;

&lt;p&gt;在让replica写入数据生效之前，coordinator还有再等一会。需要等两倍时间误差。这段时间也刚好让Paxos来同步。因为等待之后，在任意机器上发起的下一个事务的开始时间，都比如不会比这个事务的结束时间早了。然后coordinator将提交时间戳发送给客户端还有其他的replica。他们记录日志，写入生效，释放锁。&lt;/p&gt;

&lt;h3 id='id153'&gt;只读事务&lt;/h3&gt;

&lt;p&gt;对于只读事务，Spanner首先要指定一个读事务时间戳。还需要了解在这个读操作中，需要访问的所有的读的Key。Spanner可以自动确定Key的范围。&lt;/p&gt;

&lt;p&gt;如果Key的范围在一个Paxos group内。客户端可以发起一个只读请求给group leader。leader选一个时间戳，这个时间戳要比上一个事务的结束时间要大。然后读取相应的数据。这个事务可以满足外部一致性，读出的结果是最后一次写的结果，并且不会有不一致的数据。&lt;/p&gt;

&lt;p&gt;如果Key的范围在多个Paxos group内，就相对复杂一些。其中一个比较复杂的例子是，可以遍历所有的group leaders，寻找最近的事务发生的时间，并读取。客户端只要时间戳在TT.now().latest之后就可以满足要求了。&lt;/p&gt;

&lt;h3 id='id154'&gt;最后的话&lt;/h3&gt;

&lt;p&gt;本文介绍了GoogleSpanner的背景，设计和并发控制。希望不久的将来，会有开源产品出现。&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>寻找未来的架构师</title>
   <link href="http://www.baidu-ops.com/2012/09/11/find-architect-2012-q4"/>
   <updated>2012-09-11T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/09/11/find-architect-2012-q4</id>
   <content type="html">&lt;p&gt;又到了校园招聘季，你在还在为未来发展彷徨吗？还在为offer选择犹豫吗？如果你对互联网技术有极大的兴趣并渴望通过技术获得成功；如果你想驾驭云计算平台，走上职业发展的快车道；如果你想成为明天令人尊敬的系统架构师，请尽快参加百度校园招聘，申请加入领先的百度运维技术团队。&lt;/p&gt;

&lt;h2 id='id140'&gt;先听听百度架构师们怎么说：&lt;/h2&gt;

&lt;h3 id='id141'&gt;&lt;a href=''&gt;夏华夏&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img alt='夏华夏' src='/assets/themes/twitter/bootstrap/img/2012-09-11-find-architect-2012-q4/xiahuaxia.png' /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;简介&lt;/strong&gt;：百度运维部主任架构师，毕业于加州大学圣迭戈分校获得博士学位，曾就读清华大学获得学士学位，曾任职Google总部高级软件工程师，目前负责百度运维技术规划及自动化运维框架方向。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;华夏说&lt;/strong&gt;：百度运维部，为你施展自己的技术才华提供一个超大的舞台。&lt;/p&gt;

&lt;h3 id='id142'&gt;&lt;a href=''&gt;臧志&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img alt='臧志' src='/assets/themes/twitter/bootstrap/img/2012-09-11-find-architect-2012-q4/zangzhi.png' /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;简介&lt;/strong&gt;：百度运维部高级架构师，毕业于中科院软件所软件工程实验室，获得硕士学位，曾就读南京大学计算机系获得学士学位，2008年加入百度，目前负责运维自动化平台方向，在大规模集群的监控、部署、关联与调度等方面有较多的实践经验。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;臧志说&lt;/strong&gt;：海阔凭鱼跃，天高任鸟飞，加入百度，加速你的成长。&lt;/p&gt;

&lt;h3 id='id143'&gt;&lt;a href=''&gt;刘卓&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img alt='刘卓' src='/assets/themes/twitter/bootstrap/img/2012-09-11-find-architect-2012-q4/liuzhuo.png' /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;简介&lt;/strong&gt;：百度运维部高级架构师。负责百度商务系统的稳定性和运维架构优化。2007年毕业于电子科技大学固体电子工程专业获得学士学位，先后在内容广告系统、搜索广告系统负责运维技术工作。在持续部署、大规模数据传输、系统容量测量上有一定的实践经验。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;刘卓说&lt;/strong&gt;：把运维搞复杂很简单，把运维做简单很难&lt;/p&gt;

&lt;h3 id='id144'&gt;&lt;a href=''&gt;刘俊&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img alt='刘俊' src='/assets/themes/twitter/bootstrap/img/2012-09-11-find-architect-2012-q4/liujun.png' /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;简介&lt;/strong&gt;：百度运维部架构师，毕业于浙江大学生物医学工程专业获得硕士学位。2010年4月，加入百度运维部。主要负责网页搜索业务抓取系统、分布式离线系统和运维监控技术方向。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;刘俊说&lt;/strong&gt;：云计算是互联网和移动互联网的发展关键，而运维是云计算的核心；和百度运维一起，改变世界，成就梦想。&lt;/p&gt;

&lt;h3 id='id145'&gt;&lt;a href=''&gt;肖智文&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img alt='肖志文' src='/assets/themes/twitter/bootstrap/img/2012-09-11-find-architect-2012-q4/xiaozhiwen.png' /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;简介&lt;/strong&gt;：百度运维部架构师毕业于天津大学获得学士学位，2007年加入百度，目前负责分布式数据库研发方向。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;智文说&lt;/strong&gt;：百度的高速发展为员工提供了广阔的发展空间，加入百度，一起成功！  &lt;/p&gt;

&lt;h2 id='id146'&gt;逛逛百度大厦&lt;/h2&gt;

&lt;p&gt;&lt;a href='http://www.eyoubaidu.com'&gt;百度易游&lt;/a&gt;&lt;/p&gt;

&lt;h2 id='id147'&gt;申请百度运维部职位：&lt;/h2&gt;

&lt;p&gt;&lt;a href='http://tongxue.baidu.com/baidu/beijing_operation_and_maintenance_development_engineer.htm'&gt;运维开发工程师&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href='http://tongxue.baidu.com/baidu/beijing_dba.htm'&gt;数据库管理员（DBA）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href='http://tongxue.baidu.com/baidu/beijing_automation_platform_development_engineer.htm'&gt;自动化平台研发工程师&lt;/a&gt;&lt;/p&gt;

&lt;h2 id='id148'&gt;欢迎关注:&lt;/h2&gt;

&lt;p&gt;&lt;a href='http://www.baidu-ops.com/'&gt;百度运维团队技术博客&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href='http://e.weibo.com/baiduop?ref=http%3A%2F%2Fweibo.com%2Fu%2F1808038063'&gt;百度运维新浪微博&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href='http://t.qq.com/baiduop?pgv_ref=search.index.user1'&gt;百度运维腾讯微博&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;有任何疑问，还可以随时&lt;a href='mailto:op-job@baidu.com'&gt;电邮&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>[译文]puppet和capistrano 简要的对比</title>
   <link href="http://www.baidu-ops.com/2012/09/04/puppet-vs-capistrano"/>
   <updated>2012-09-04T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/09/04/puppet-vs-capistrano</id>
   <content type="html">&lt;p&gt;&lt;a href='http://www.agileweboperations.com/puppet-vs-capistrano-short-comparison'&gt;原文地址&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;我们现在不仅使用&lt;a href='https://github.com/capistrano/capistrano/wiki'&gt;capistrano&lt;/a&gt;部署Ruby on Rails的应用，也用来安装和管理我们的物理服务器和虚拟（基于Xen）服务器。我们编写capistrano的recipe用来添加用户，安装apache和mysql，配置Xen虚拟机等等。邂逅了&lt;a href='http://www.agileweboperations.com/configuration-management-introduction-to-puppet'&gt;puppet&lt;/a&gt;，我开始惊讶他们之间本质的不同。puppet宣称能够让用户自动化管理服务器，扩展集群，这个目标我们已经通过实现定制的capistrano recipe实现了。那么，他们之间的不同是什么呢？&lt;/p&gt;

&lt;h2 id='id136'&gt;设计目标&lt;/h2&gt;

&lt;p&gt;首先，我尝试理解这两个工具的设计目标。capistrano开发出来是为了部署rails应用。当然，他非常易于扩展而像我们一样用来管理服务器，像&lt;a href='http://deprec.org'&gt;deprec&lt;/a&gt;这样的recipe汇集网站已经为capistrano提供了这些功能，但是，capistrano最基本的功能仍是部署。&lt;/p&gt;

&lt;p&gt;puppet不同于capistrano，他一开始作为生命周期管理工具问世。他提供了定义服务间依赖和服务预期状态的能力，例如，一个配置文件描述apache应处于运行中，其运行需要依赖一些包。然后puppet自动化的达到你所设定的这个状态。这个不同的设计目的，使我们使用两个工具的方式是如此的不同。&lt;/p&gt;

&lt;h2 id='id137'&gt;使用方法&lt;/h2&gt;

&lt;p&gt;capistrano的recipe使用命令式的方法描述如何做。capistrano的recipe展现了系统上“动态”的视图。你能看到配置是如何一步步变化的。capistrano的recipe解答了“我想做什么”的问题。&lt;/p&gt;

&lt;p&gt;puppet用声明的方法描述系统预期的状态。puppet的manifest解答了“他看起来应该是怎样的”的问题。puppet从这份配置中生成步骤，并自动的应用系统上。&lt;/p&gt;

&lt;h2 id='id138'&gt;特性对比&lt;/h2&gt;

&lt;p&gt;我发现了他们之间一些有趣的特性，整理成一个列表，目前还不完整，希望起到一个概览的作用。&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;特性&lt;/th&gt;&lt;th&gt;puppet&lt;/th&gt;&lt;th&gt;capistrano&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;配置语言&lt;/td&gt;&lt;td style='text-align: left;'&gt;&amp;#8221;元&amp;#8221;语言（自己写的DSL）&lt;/td&gt;&lt;td style='text-align: left;'&gt;Ruby&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;dry-run模拟执行&lt;/td&gt;&lt;td style='text-align: left;'&gt;有&lt;/td&gt;&lt;td style='text-align: left;'&gt;有（2.5+）&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;幂等&lt;/td&gt;&lt;td style='text-align: left;'&gt;是&lt;/td&gt;&lt;td style='text-align: left;'&gt;否&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;对事务的支持&lt;/td&gt;&lt;td style='text-align: left;'&gt;支持&lt;/td&gt;&lt;td style='text-align: left;'&gt;支持&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;回滚&lt;/td&gt;&lt;td style='text-align: left;'&gt;不支持&lt;/td&gt;&lt;td style='text-align: left;'&gt;支持&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;随机监控服务器&lt;/td&gt;&lt;td style='text-align: left;'&gt;不支持&lt;/td&gt;&lt;td style='text-align: left;'&gt;支持&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;操作模式&lt;/td&gt;&lt;td style='text-align: left;'&gt;daemon进程拉取配置&lt;/td&gt;&lt;td style='text-align: left;'&gt;用户推&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;定义依赖&lt;/td&gt;&lt;td style='text-align: left;'&gt;service，packages，files复杂依赖&lt;/td&gt;&lt;td style='text-align: left;'&gt;dir,writablity,command,gem,regex的单向依赖&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;解决依赖&lt;/td&gt;&lt;td style='text-align: left;'&gt;自动&lt;/td&gt;&lt;td style='text-align: left;'&gt;手工&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id='id139'&gt;结论&lt;/h2&gt;

&lt;p&gt;puppet 和 capistrano 处于不同的层，puppet更多的处理依赖的管理而不是脚本任务。在通常场景下，puppet 负责保证特定的系统配置，capistrano负责动态的步骤，像部署应用的新版本或者随机监控服务器（ad-hoc server monitoring）。但从我的经验和deprec上展示的脚本，capistrano能对配置系统起到很大的帮助。&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>[译文]stallman其人轶事</title>
   <link href="http://www.baidu-ops.com/2012/08/26/stallman-facts"/>
   <updated>2012-08-26T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/08/26/stallman-facts</id>
   <content type="html">&lt;p&gt;&lt;a href='http://stallmanfacts.com/'&gt;原文地址&lt;/a&gt;,&lt;/p&gt;

&lt;h2 id='top10'&gt;top10&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman 的胡子是由括号组成的&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman&amp;#8217;s beard is made of parentheses.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman 自己就是GNU的标志&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman is the sole poster on /g/&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman 从不洗澡，他只执行&amp;#8217;make clean&amp;#8217;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman never showers: he runs &amp;#8216;make clean&amp;#8217;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman 使用16进制编辑器编译了gcc的第一个版本&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman compiled the first version of gcc with an hexadecimal editor.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Richard Stallman 能触摸MC Harmmer&lt;/p&gt;

&lt;p&gt;zerd：双关MC Harmmer的成名曲是&amp;#8221;U Can&amp;#8217;t Touch This&amp;#8221;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman can touch MC Hammer&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman 通过免费解决了旅行销售员的问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman solved the travelling salesman problem by making everything free.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&amp;#8216;RMS&amp;#8217;中的&amp;#8217;R&amp;#8217;代表&amp;#8217;RMS&amp;#8217;&lt;/p&gt;

&lt;p&gt;zerd: RMS是Richard Stallman的名字首字母缩写&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;The R in RMS stands for RMS.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&amp;#8216;RMS&amp;#8217;脸上的毛发是胡子中免费的。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;rms&amp;#8217; facial hair is &amp;#8220;free as in beard&amp;#8221;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman 愤怒时他不仅诅咒，还是递归的诅咒.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;When Richard Stallman gets pissed off he doesn&amp;#8217;t swear, he recurses.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;锁定供应商是指供应商把自己锁在建筑物中以远离Richard Stallman的愤怒。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Vendor lock-in is when vendors lock themselves inside of a building out of fear of Richard Stallman&amp;#8217;s wrath.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id='id135'&gt;其余的&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman 编写了 &lt;a href='http://www.douban.com/group/topic/1234338/'&gt;Chuck Norris&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman programmed Chuck Norris&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;当Richard Stallman 注视windows时，它发生了段错误。当Richard Stallman未注视windows时，它也发生了段错误。&lt;/p&gt;

&lt;p&gt;Whenever Richard Stallman looks at a Windows computer, it segfaults. Whenever Richard Stallman doesn&amp;#8217;t look at a Windows computer, it segfaults.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Richard Stallman 用0和1记笔记&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman takes notes in binary.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Richard Stallman的左手叫做&amp;#8221;(&amp;#8220;,右手叫做&amp;#8221;)&amp;#8221;.&lt;/p&gt;

&lt;p&gt;zerd: lisp语言书写出来有大量的&amp;#8221;()&amp;#8221;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman&amp;#8217;s left and right hands are named &amp;#8220;(&amp;#8221; and &amp;#8221;)&amp;#8221;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman 能编写防病毒程序来治愈爱滋病。但他从不写防病毒程序。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman can write an anti-virus program that cures HIV. Too bad he never writes anti-virus programs.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman 用Emacs写了第一版的Emacs。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman wrote the first version of Emacs using Emacs.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Richard Stallman 写了一个非常强大的程序，他知道宇宙的终极秘密。&lt;/p&gt;

&lt;p&gt;zerd：&lt;a href='http://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Answer_to_the_Ultimate_Question_of_Life.2C_the_Universe.2C_and_Everything_.2842.29'&gt;42&lt;/a&gt;是科幻小说中&amp;#8221;Deep Thought&amp;#8221;技术出的一个数字，解答了宇宙完事万物的秘密。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman wrote a program so powerful, it knows the question to 42.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman发现了外星生命，但是他杀了他们因为他们使用商业软件。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman discovered extra-terrestrial life but killed them because they used closed-source software.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;人们查杀病毒，病毒查杀Richard Stallman。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Some people check their computers for viruses. Viruses check their computers for Richard Stallman.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman 为上帝写了编译器。大爆炸就是宇宙第一次发生“段错误”&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman wrote the compiler God used. The Big Bang was the Universe&amp;#8217;s first segfault.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Richard Stallman 的理想还未实现&lt;/p&gt;

&lt;p&gt;zerd：这句没看懂。wget是linux下的一个程序。w－get对应w－demand，Stallman的思想是free software，目前还没有实现。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman doesn&amp;#8217;t wget, Richard Stallman wdemands!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman 能用正则表达式解析HTML。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman can parse HTML with regex.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Richard Stallman 不需要sudo，我反正要给他做一个三明治&lt;/p&gt;

&lt;p&gt;zerd: 真的没看懂&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman doesn&amp;#8217;t need sudo. I will make him a sandwich anyway.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Stallman 家里没有windows，即使门上也没有&lt;/p&gt;

&lt;p&gt;zerd：stallman家里没有窗户，呵呵&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;There is no Windows in Stallman&amp;#8217;s house.. just DOORs&amp;#8230;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;和正常出生的小孩不一样，Richard Stallman 是以多态的方式实例化了自己，不久他就长出了胡子。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Rather than being birthed like a normal child, Richard Stallman instead instantiated himself polymorphically. Shortly thereafter he grew a beard.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;在起居室里有1242个对象(包括这间屋子)可供RMS编写OS&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;In an average living room there are 1,242 objects RMS could use to write an OS, including the room itself.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Richard Stallman 能够telnet上Mordor&lt;/p&gt;

&lt;p&gt;zerd： Mordor 魔多&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman can telnet into Mordor&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman 不用浏览器，他发送link给daemon，由它通过wget获取页面并传回给Stallman&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman doesn&amp;#8217;t use web browsers, he sends a link to a demon that uses wget to fetch the page and sends it back to him.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman 使用GNU FDL协议发布了自己的DNA&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman released his own DNA under GNU FDL.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Richard Stallman 没有手机，因为它能对着粗糙的凸盘发出臭氧层的共振频率，抵达接受者的上空。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Richard Stallman does not own a mobile phone because he can fashion a crude convex dish and shout into it at the exact resonant frequency of the ozone, causing a voice to seemingly come from the sky above his intended recipient.&lt;/p&gt;
&lt;/blockquote&gt;</content>
 </entry>
 
 <entry>
   <title>本站供稿须知</title>
   <link href="http://www.baidu-ops.com/2012/08/26/how-to-write-post-for-this-site"/>
   <updated>2012-08-26T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/08/26/how-to-write-post-for-this-site</id>
   <content type="html">&lt;h2 id='id133'&gt;基本说明&lt;/h2&gt;

&lt;p&gt;本站点是使用&lt;a href='http://jekyllrb.com'&gt;jekyll&lt;/a&gt;搭建。 文章的格式是&lt;a href='http://www.markdown.tw'&gt;Markdown&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这是其中一篇文章的&lt;a href='https://raw.github.com/zerdliu/www.baidu-ops.com/master/_posts/2012-08-21-disk-to-memory.md'&gt;源码&lt;/a&gt;,转换后的页面样式在&lt;a href='http://www.baidu-ops.com/2012/08/21/disk-to-memory/'&gt;这里&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;每篇post的开头都有如下一部分代码,说明如下 Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;文章中如果涉及图片,将图片按照含义命名（英文）好，然后放在一个目录里面。&lt;/p&gt;

&lt;p&gt;如果不了解git及分布开发，至少需要提供一个xxx.md的文档，以减轻主编人肉编辑压力。&lt;/p&gt;

&lt;h2 id='id134'&gt;深入&lt;/h2&gt;

&lt;p&gt;本站点托管在github上。可以fork到本地进行编辑。&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>bash的常用功能和技巧</title>
   <link href="http://www.baidu-ops.com/2012/08/25/shell-tricks"/>
   <updated>2012-08-25T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/08/25/shell-tricks</id>
   <content type="html">&lt;h2 id='id123'&gt;编码规范&lt;/h2&gt;

&lt;p&gt;1 对命令的返回值进行判断 2 临时文件采用脚本名加PID标识并清理 &lt;br /&gt;3 function内的局部变量使用local限定符 &lt;br /&gt;4 显式函数返回return脚本退出exit &lt;br /&gt;5 变量名用&lt;code&gt;${}&lt;/code&gt;括起来 &lt;br /&gt;6 命令替换使用&lt;code&gt;$()&lt;/code&gt;而不是反引号 &lt;br /&gt;7 将变量写在脚本头或者独立成配置&lt;/p&gt;

&lt;h2 id='id124'&gt;参数处理&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;直接使用$0,$1……，$@，$#&lt;/li&gt;

&lt;li&gt;通过eval赋值&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通过set改变环境变量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;则可以通过$1的值为var1，$#的值为3。这种方法改变了环境变量，慎重。或者在subshell中使用&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;getopts&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id='subshell'&gt;理解subshell/子进程&lt;/h2&gt;

&lt;p&gt;子进程可以继承父进程的环境变量 Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;和&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;“|”创建了一个子进程，无法将变量传给父shell&lt;/p&gt;

&lt;h2 id='here'&gt;文本使用here文档&lt;/h2&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;利用End_mail前面的”-”可以使用tab进行缩进，保持脚本可读&lt;/p&gt;

&lt;h2 id='id125'&gt;避免常见陷阱&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;避免shell参数个数限制&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;避免test测试错误&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;3. 避免变量未初始化错误&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;避免cd引起路径错误&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;5. 更加安全的使用$@&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;6. 避免进程异常退出&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;crontab中的元字符&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;规避xargs的默认分割行为&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;9. 避免拷贝错误：&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;h2 id='id126'&gt;理解文件描述符&lt;/h2&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;h2 id='id127'&gt;命令分组&lt;/h2&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;h2 id='id128'&gt;字串替换&lt;/h2&gt;

&lt;p&gt;说明： #前%后，控制字串截取方式 实例：当前目录下有如下文件&lt;/p&gt;

&lt;p&gt;&lt;code&gt;host.new offline.new online.new rd.new wugui64.new xferlog.new&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;需要将后缀.new去掉&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;h2 id='id129'&gt;进程替换&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;()&lt;/code&gt; 将进程的输出替换为文本做标准输入&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;同时从文件和标准输入获取： Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;另外一种方式&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;实例：diff两台服务器的同一个配置文件 Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;h2 id='wget'&gt;wget使用&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;不要随便修改-t -T选项的设置&lt;/li&gt;

&lt;li&gt;限制使用&lt;code&gt;*&lt;/code&gt;，失败后返回值仍为0&lt;/li&gt;

&lt;li&gt;注意加-c和不加-c的程序行为&lt;/li&gt;

&lt;li&gt;从线上下载数据要加&amp;#8211;limit-rate=10M&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id='ssh'&gt;ssh的使用&lt;/h2&gt;

&lt;p&gt;非交互使用ssh，最好加-n参数&lt;/p&gt;

&lt;p&gt;file文件的内容为：&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;远程使用vim，加-t参数，分配tty 超时，重试参数 Liquid error: No such file or directory - posix_spawnp 使用rsync前，加&amp;#8211;dry-run参数 scp加-p参数，保持文件时间戳一致，利用浏览器缓存&lt;/p&gt;

&lt;h2 id='find'&gt;find的使用&lt;/h2&gt;

&lt;p&gt;1. 排除目录 Liquid error: No such file or directory - posix_spawnp 2. 精确判断时间 Liquid error: No such file or directory - posix_spawnp 3. 运行命令 Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;h2 id='id130'&gt;分离会话&lt;/h2&gt;

&lt;p&gt;1 nohup&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;2 disown：命令敲下去发现忘记nohup了怎么办？使用disown补救 3 screen：在wiki中搜一下&lt;/p&gt;

&lt;h2 id='id131'&gt;创建安全和可维护的脚本&lt;/h2&gt;

&lt;p&gt;1 供其他进程使用的文件生成时 采用更名再mv的方式 如 Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;2 将函数和配置独立成单独的脚本&lt;/p&gt;

&lt;p&gt;3 将不同服务器需要差异对待的变量提取成单独的配置文件&lt;/p&gt;

&lt;p&gt;4 日志打印必须包含脚本名&lt;code&gt;basename&lt;/code&gt;和时间&lt;/p&gt;

&lt;p&gt;5 每步骤必须校验返回值&lt;/p&gt;

&lt;p&gt;6 脚本中避免使用&lt;code&gt;*&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;7 保持缩进4个空格&lt;/p&gt;

&lt;p&gt;8 过长的命令按照&lt;code&gt;|&lt;/code&gt;折行&lt;/p&gt;

&lt;p&gt;9 创建目录使用&lt;code&gt;mkdir –p&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;10 如果采用后台运行一定要wait： &lt;code&gt;( command1 ; command2 ) &amp;amp; wait&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;11 对于需要获取命令输出的命令需要将&lt;code&gt;stderr&lt;/code&gt;屏蔽到&lt;code&gt;/dev/null&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;12 抽离公共逻辑作为函数或者代码片段（导入变量）&lt;/p&gt;

&lt;p&gt;13 保证互斥和脚本实例唯一性&lt;/p&gt;

&lt;h2 id='id132'&gt;参考资料&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href='http://tldp.org/LDP/abs/html/'&gt;Abs&lt;/a&gt; &amp;#8211; advanced bash scripting guide&lt;/li&gt;

&lt;li&gt;&lt;a href='http://docstore.mik.ua/orelly/unix/upt/index.htm'&gt;unix power tools&lt;/a&gt; &amp;#8211; unix超级工具上、下&lt;/li&gt;
&lt;/ol&gt;</content>
 </entry>
 
 <entry>
   <title>如何做一名优秀的运维工程师--职称能力要求解读</title>
   <link href="http://www.baidu-ops.com/2012/08/25/how-to-be-a-good-operation-engineer"/>
   <updated>2012-08-25T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/08/25/how-to-be-a-good-operation-engineer</id>
   <content type="html">&lt;p&gt;&lt;a href='/assets/themes/twitter/bootstrap/pdf/how-to-be-a-good-operation-engineer.pdf'&gt;本文的对应ppt&lt;/a&gt;&lt;/p&gt;

&lt;h2 id='id115'&gt;等级与能力&lt;/h2&gt;

&lt;h3 id='t4'&gt;T4需要具备什么样的能力？&lt;/h3&gt;

&lt;h4 id='id116'&gt;你熟练掌握运维基础技能么？&lt;/h4&gt;

&lt;p&gt;如（仅举例）: SSH的原理是什么？如何保证安全性？什么是非对称加密？什么是中间人攻击？SSH是如何避免中间人攻击的？这个特性对传输正确性有哪些影响？known_hosts和中间人攻击是什么关系？为什么里面写的密钥和我写到远程的公钥不一致？这个密钥又是什么？会有什么影响？&lt;/p&gt;

&lt;h4 id='id117'&gt;你了解服务么？&lt;/h4&gt;

&lt;p&gt;你的服务的瓶颈在哪？容量是多少？有多少指标是你关注的，哪个指标现在处于有风险的状态，你的服务器每个时刻都在做什么？能够通过曲线图读出目前系统所处的状态或者正在执行的任务么？常用的模块间的连接策略和负载均衡策略有哪些？每种的优势和缺点是什么？你的服务适合使用哪种策略？&lt;/p&gt;

&lt;h4 id='id118'&gt;你是一个合格的管理员么？&lt;/h4&gt;

&lt;p&gt;线上的每一个细节都知道么？有哪些种任务调度的方式？分别适合哪些场景？你的服务是什么样的？有没有重复的代码，和不一致的脚本？举几个例子？你的服务是“干净”的屋子，还是一个“肮脏”的杂物堆？你能给新人讲清楚服务的细节么？你带的新人踩过坑么？&lt;/p&gt;

&lt;p&gt;如果上述三个问题的回答是yes。并且能够在你做的运维工作中结合自己的知识能够有效的解决问题。那么你具备T4工程师的能力了。这是一个必要非充分条件！！&lt;/p&gt;

&lt;h3 id='t5'&gt;T5需要具备什么样的能力？&lt;/h3&gt;

&lt;p&gt;当到达T4的时候，已经积累的足够的经验，包括在运维技能上的，服务上的，成本和效率上的考虑。&lt;/p&gt;

&lt;p&gt;在遇到一个比较复杂的问题上。要能够有自己的思考和分析了。什么样的情况，该选择什么样的方案解决问题。每个方案的特性是什么？不要说你的方案好，这个方案的缺陷是什么？会引发哪些新的问题？引发的这些新问题该如何的去解决？什么时候开始解决？什么时候我的方案已经不适宜了，该被推翻重来了？当你在提出一个方案的时候，能够很好的回答这样的问题。那么你已经具备了权衡的能力。那么说你已经有的经验，你的思维判断能力能够支持你解决比较复杂的问题了。没有完美的方案，如果能够针对比较复杂的问题。采取有效的折中，突出方案的有点，弱化方案的缺点。要时刻记住一点。没有完美的方案。但是有美的、简单方案。如果用简单的、美的、有效的方式解决了问题。能够带领工程师完成工作。这是T5应该有的能力。&lt;/p&gt;

&lt;p&gt;以数据存储方案为例。为什么选择左面的方案而没有选择右面的方案。有哪些条件？数据支撑是什么？左边的方案为什么选择mfs，而没有选择hdfs，数据支撑？论据支撑？为什么选择入口服务器，而不是直接mount磁盘，存在的风险是什么？数据是？为什么选择4台入口机，而不是3台，5台？为什么选择lvs，而不是bvs？mfs的副本对下载速率有哪些影响？改选择多少副本？有数据么？整个方案穿透了都少层？哪层会先成为瓶颈？什么时间，达到什么条件，我们可以过渡到右边的方案，前期需要做什么？如果遇到风险我们该怎么办？能够通过有效的方式监测和预知风险么？&lt;/p&gt;

&lt;h3 id='t6'&gt;T6以上需要什么样的能力？&lt;/h3&gt;

&lt;p&gt;需要更多的技术积累。积累先进的技术，跨工种的技术。比如：系统底层的原理，如何提高编程的效率，快速实现自己的想法？什么是design？如何做好的设计？我们的测试团队都在做什么？如何保证软件质量？软件质量只是QA的事情么？我们日常使用的运维工具，哪些是合理的？哪些是不合理的？什么样的系统是美的？如何以最简洁的方式解决一个问题？为什么搜索广告是key word-&amp;gt;ad ， 而网盟是url-&amp;gt;key word-&amp;gt;ad？研发工程师做的运维方面设计决策是否是合理的？我们的理由上和数据上的支撑是什么？&lt;/p&gt;

&lt;p&gt;listhost设计的初衷，设计的折中？有哪些特性和缺点？作者的考虑是什么？如果没有listhost呢？同样的问题，服务树呢？如果你只能告诉我5点，我认为深入思考的还不够。数据传输有哪些种方式，什么时候选择推，什么时候选择拉，之间的区别又是什么？gingko对kfp的改进是什么？gingko和kfp对数据传输脚本设计有哪些影响？&lt;/p&gt;

&lt;p&gt;足够的积累+解决问题+影响别人 = T6，T7&amp;#8230;&amp;#8230;&lt;/p&gt;

&lt;h2 id='id119'&gt;更正一些错误的理解&lt;/h2&gt;

&lt;h3 id='id120'&gt;关于好的产品：&lt;/h3&gt;

&lt;p&gt;一个成功的产品（系统，工具，尤其是底层的）一开始都是在满足自己的需求。在把自己的问题很好的解决了之后，发现它确实是一个伟大的产品。linux，git，perl，ruby都是这样。当然也不是说不要胸怀大志，只顾解决自己的问题。同样，这也不是一个好的工程师。理想的情况应该是，先把自己的问题解决掉（用功能和代码抽象等等技术），在解决问题的同时兼顾别人对同样的问题的看法和需求。一个工具和解决方案必有它的优势和弱项。如果一开始就想去解决所有人的问题，那必将得到一个毫无特色的，处处充满妥协的产品。最有多问问自己，你有没有“真正”“好”的解决了自己的问题？&lt;/p&gt;

&lt;h3 id='id121'&gt;为脚本正身：&lt;/h3&gt;

&lt;p&gt;说道这里，我想说一下“脚本”。“脚本”指的是用python，perl，ruby，shell等语言写出来的工具。在我们眼中貌似成了一个贬义词。一个解决方案如果是脚本的，就会被认为功能低下，无法复用，简单临时的拼凑。（不知道大家是否都存有这样的偏见，但在我周围的环境中是有的）。我想在这里为“脚本”正正身。一门语言，我们不能够简单说他好与不好。不能说c就是好的，脚本就是不好的。关键在于如何使用，在什么场景下使用，写的是一个没有参数处理，没有文档，没有异常处理，没有单元测试的脚本肯定不是一个好的脚本。&lt;/p&gt;

&lt;h3 id='id122'&gt;破除浮华的“平台”：&lt;/h3&gt;

&lt;p&gt;“平台”虚无缥缈，只要是工程师工作的&amp;#8221;界面&amp;#8221;，都可以认为是“平台”，比如linux是一个操作系统平台，git是源码管理的平台。我们对“平台”的看法是偏执的，但我们指的“平台”大多是web的平台，要登陆，有花哨的人机交互界面。但是缺少编程交互接口。部分工程师还引以自豪学会了javascript。但是你的问题是否需要用web的解决方案来解决？能不能用工具就搞定了？如果，我是说如果，必须要开发web，有没有考虑面向资源的web？开发RESTful的web？引入一些框架，提高开发效率。有多少项目大家在排期的时候都是按照半年排期的？原因就是一个web，一个所谓的“系统”。我曾经在主机管理工具中尝试引入rails开发web，2个小时主体的功能就完成了。完成了页面，数据库设计，同时支持API，能够直接通过curl添加、修改、删除、查询。如果必须开发web，那么至少是这样的web。&lt;/p&gt;

&lt;p&gt;推荐一本小书&amp;#8211;“&lt;a href='http://www.amazon.com/Are-Your-Lights-On-Problem/dp/0932633161/ref=sr_1_1?ie=UTF8&amp;amp;qid=1345866883&amp;amp;sr=8-1&amp;amp;keywords=are+your+light+on'&gt;你的灯亮着么？&lt;/a&gt;”，中文版已经绝版，&lt;a href='http://pic1.zcom.com/u/attachment/mag/20090317/73512_1237271841AENF.pdf'&gt;这儿&lt;/a&gt;有部分中文翻译。主要是教你如何定义问题，看待问题，解决问题，思考问题的奇书。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;简短说明：这是一本关于“问题”的书。问题的产生，问题的解决方式，问题的演化等等。从这本书中我学到了：问题不能够被解决，只能够被转化。在我每次遇到问题解决问题的时候这句话都受益匪浅。这是一本建议大家每年都要读一遍的“小书”，每次读完后都会有新知。&lt;/code&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>ssh hang 问题追查</title>
   <link href="http://www.baidu-ops.com/2012/08/24/ssh-hang-solved"/>
   <updated>2012-08-24T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/08/24/ssh-hang-solved</id>
   <content type="html">&lt;h2 id='id111'&gt;问题表现&lt;/h2&gt;

&lt;p&gt;Log平台短期内两次出现多个统计任务ssh hangg住的问题。具体症状就是：ssh执行机执行脚本时，比如：&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;这个命令理应很快返回结果，但问题是hang住了，直到50分钟后被系统检测到才被杀死重跑。严重影响任务的完成时间，对下游用户造成了影响，需要马上解决。相信这个问题大家在工作中都有遇到过吧？&lt;/p&gt;

&lt;h2 id='id112'&gt;问题分析&lt;/h2&gt;

&lt;p&gt;经过统计，我们发现，这个问题80%的概率是发生在跨地域交互，我们初步怀疑跟网络问题有关。&lt;/p&gt;

&lt;p&gt;我们已经知道是ssh的服务出现问题，我们先查看了我们的机器的网卡情况，看看是不是由于我们网卡打满出现了瓶颈问题造成的，经过排查网卡在出现问题的时段没有问题。然后我们考虑可能是长距离网络传输问题造成了上述的问题，于是我们联系了网络组的人，沟通了一下在这个时段是不是有网络的变动，经过网络组的排查确实在这两次的服务出现的问题的时间段里都做了网络的调整，这样可以得出一个猜测，可能是由于网络的调整造成了网络抖动，部分数据包丢失，从而导致ssh-hang的发生，基于上面的猜测，我们通过wiki和网上搜索了相关文档发现，修改配置的以下几个参数：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/etc/ssh/ssh_config&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;可以解决问题，于是我们做了相应的修改，结果很显著，ssh-hang的问题发生的概率减少了90%左右，可是还会出现ssh-hang的问题，问题还是没有彻底的解决。既然是网络丢包导致的问题，我们就对网络进行监控，追查到底是哪里出现的问题，首先我们建立一个专门监控ssh-hang的监控策略，并且开始抓包实时监控中控机的22号端口，这样一旦再次出现ssh-hang的问题我们就会第一时间捕捉问题现场，追查原因。&lt;/p&gt;

&lt;h2 id='id113'&gt;问题定位&lt;/h2&gt;

&lt;p&gt;在又一次的网络调整的时段，ssh hang 的问题如约而至，我们迅速定位了问题。凌晨的时候又发生了任务hang住的问题，通过抓包得到的数据，分析出任务hang在系统调用：&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;read的时候，在对应的/proc/PID/fd下，6对应的是一个socket&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;也就是说由于socket:&lt;span&gt;2606004771&lt;/span&gt;包的丢失，造成了这次的ssh-hang的问题，问题出现在read函数这，我们log组就追查了openssh的源码，了解到在4.9版本前存在一个bug： ssh命令执行时，如果在ssh_connect 之后，但在ssh_exchange_identification交换之前出现网络问题，则ssh client可能会hang住（因为socket在ssh_exchange_identification之后才设置为nonblocking状态），后来我们分析openssh3.9p1的源码得出：&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp 在3.9p1源码中，如果hang住发生在ssh_connect中（如远程机器禁用了客户端的ip），那么可以设置ConnectTimeout从而在ssh_connect阶段就能发现问题并解决。如果修改ServerAliveInterval，则在ssh_login的后续执行过程中，连接忽然失效的情况可以timeout；也就是我们之前设置的参数是针对解决这两个问题的，但本次hang住在read系统调用中，openssh的read调用不多，其中在ssh_login函数的ssh_exchange_identification有read函数读取socket，由于在此时未将socket设置为nonblock状态，因此就可能阻塞，而且在这个版本中，没有参数可以阻止这种情况导致的hang住的问题，在4.9以后的版本中这个bug得到了修正，现在看只能通过升级openssh的版本来解决这个问题了。&lt;/p&gt;

&lt;h2 id='id114'&gt;问题总结&lt;/h2&gt;

&lt;p&gt;在公司网络核心交互日益增多的情况下，网络抖动这类情况不可避免的会发生，ssh是大家每天必用的工具，而且很多任务的提交也用了ssh，这个问题的定位解决发出来希望对大家有一定参考意义.&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>mysql timeout调研与实测</title>
   <link href="http://www.baidu-ops.com/2012/08/24/mysql-timeout"/>
   <updated>2012-08-24T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/08/24/mysql-timeout</id>
   <content type="html">&lt;p&gt;接触网络编程我们不得不提的就是超时，TCP建立连接的超时，数据报文发送/接收超时等等，mysql在超时上也做足了功夫。&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Variable_name&lt;/th&gt;&lt;th&gt;Default Value&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;connect_timeout&lt;/td&gt;&lt;td style='text-align: left;'&gt;5&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;interactive_timeout&lt;/td&gt;&lt;td style='text-align: left;'&gt;28800&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;net_read_timeout&lt;/td&gt;&lt;td style='text-align: left;'&gt;30&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;net_write_timeout&lt;/td&gt;&lt;td style='text-align: left;'&gt;60&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;wait_timeout&lt;/td&gt;&lt;td style='text-align: left;'&gt;28800&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;上面这5个超时是本次调研的重点，当然MySQL绝对不指这5种超时的配置，由于经历和时间有限，本次只谈这5种。&lt;/p&gt;

&lt;h2 id='connect_timeout'&gt;Connect_Timeout&lt;/h2&gt;

&lt;p&gt;这个比较好理解，字面上看意思是连接超时。&amp;#8221;The number of seconds that the mysqld server waits for a connect packet before responding with Bad handshake&amp;#8221;。&lt;/p&gt;

&lt;p&gt;MySQL连接一次连接需求经过6次“握手”方可成功，任意一次“握手”失败都有可能导致连接失败，如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img alt='mysql_handshake' src='/assets/themes/twitter/bootstrap/img/mysql-timeout/mysql_handshake.png' /&gt;&lt;/p&gt;

&lt;p&gt;前三次握手可以简单理解为TCP建立连接所必须的三次握手，MySQL无法控制，更多的受制于不TCP协议的不同实现，后面的三次握手过程超时与connect_timeout有关。简单的测试方法：&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;Telnet未退出前通过show processlist查看各线程状态可见，当前该连接处于授权认证阶段，此时的用户为“unauthenticated user”。细心的你懂得，千万不要干坏事。&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;h2 id='wait_timeout'&gt;wait_timeout&lt;/h2&gt;

&lt;p&gt;等待超时，那mysql等什么呢？确切的说是mysql在等用户的请求(query)，如果发现一个线程已经sleep的时间超过wait_timeout了那么这个线程将被清理掉，无论是交换模式或者是非交换模式都以此值为准。&lt;/p&gt;

&lt;p&gt;注意：wait_timeout是session级别的变量哦，至于session和global变量的区别是什么我不说您也知道。手册上不是明明说wait_timeout为not interactive模式下的超时么？为什么你说无论是交换模式或者非交换模式都以此值为准呢？简单的测试例子如下：&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;那为什么手册上说在交互模式下使用的是interactive_timeout呢，原因如下：&lt;/p&gt;

&lt;p&gt;check_connection函数在建立连接初期，如果为交互模式则将interactive_timeout值赋给wait_timeout，骗您误以为交互模式下等待超时为interactive_timeout 代码如下:&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;h2 id='interactive_timeout'&gt;interactive_timeout&lt;/h2&gt;

&lt;p&gt;上面说了那么多，这里就不再多做解释了。我理解mysql之所以多提供一个目的是提供给用户更灵活的设置空间。&lt;/p&gt;

&lt;h2 id='net_write_timeoutite_timeout'&gt;net_write_timeoutite_timeout&lt;/h2&gt;

&lt;p&gt;看到这儿如果您看累了，那下面您得提提神了，接下来的两个参数才是我们遇到的最大的难题。 &amp;#8220;The number of seconds to wait for a block to be written to a connection before aborting the write.&amp;#8221; 等待将一个block发送给客户端的超时，一般在网络条件比较差的时，或者客户端处理每个block耗时比较长时，由于net_write_timeout导致的连接中断很容易发生。下面是一个模拟的例子：&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;h2 id='net_read_timeout'&gt;net_read_timeout&lt;/h2&gt;

&lt;p&gt;“The number of seconds to wait fprintfor more data from a connection before aborting the read.”。Mysql读数据的时的等待超时，可能的原因可能为网络异常或客户端or服务器端忙无法及时发送或接收处理包。这里我用的是iptables来模拟网络异常，生成一个较大的数据以便于给我充足的时间在load data的过程中去配置iptables规则。&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;执行完iptables命令后show processlist可以看到load data的连接已经被中断掉了，但因为这里我选择了myisam表，所以&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;可以看到数据还是被插入了一部分。&lt;/p&gt;

&lt;h2 id='net_retry_count'&gt;net_retry_count&lt;/h2&gt;

&lt;p&gt;&amp;#8220;超时&amp;#8221;的孪生兄弟“重试”，时间原因这个我没有进行实际的测试，手册如是说，估且先信它一回。&lt;/p&gt;

&lt;p&gt;If a read or write on a communication port is interrupted, retry this many times before giving up. This value should be set quite high on FreeBSD because internal interrupts are sent to all threads.&lt;/p&gt;

&lt;p&gt;On Linux, the &amp;#8220;NO_ALARM&amp;#8221; build flag (-DNO_ALARM) modifies how the binary treats both net_read_timeout and net_write_timeout. With this flag enabled, neither timer cancels the current statement until after the failing connection has been waited on an additional net_retry_count times. This means that the effective timeout value becomes&amp;#8221; (timeout setting) × (net_retry_count+1)&amp;#8221;.&lt;/p&gt;

&lt;p&gt;FreeBSD中有效，Linux中只有在build的时候指定NO_ALARM参数时net_retry_count才会起作用。&lt;/p&gt;

&lt;p&gt;说明：目前线上使用的版本都未指定NO_ALARM。&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>荐文二则-2</title>
   <link href="http://www.baidu-ops.com/2012/08/24/articles-2"/>
   <updated>2012-08-24T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/08/24/articles-2</id>
   <content type="html">&lt;h3 id='scaling'&gt;第一篇关于scaling&lt;/h3&gt;

&lt;p&gt;&amp;#8221;&lt;a href='http://goo.gl/DdYXT'&gt;Zen and the Art of Scaling - A Koan and Epigram Approach&lt;/a&gt;&amp;#8221;&lt;/p&gt;

&lt;p&gt;是关于分布式系统的可扩展性设计的文章。作者Russell Sullivan曾 在多家公司任软件架构师，并创立了Freelancer公司；他有着多年的分布式数据库开发的研发经验，目前在开发AlchemyDatabase，一个兼有关系数据管理和NOSQL的 复合型数据库。Russell从多年的实践中总结了44条构建高性能、高可扩展的分布式系统的经验教训。这44条不一定全是正确的，但却值得我们去仔细思考。例如:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;第6条“可扩展是一种(在性能、功能间的)妥协”&lt;/li&gt;

&lt;li&gt;第7条用可配置变量代替hardcoded变量&lt;/li&gt;

&lt;li&gt;第31条对数据进行压缩等等&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id='trace_google2010_'&gt;第二篇关于trace ，是Google于2010年 发表的论文&lt;/h3&gt;

&lt;p&gt;&amp;#8221;&lt;a href='http://goo.gl/S6trs'&gt;Dapper, A Large-Scale Distributed Systems Tracing Infrastructure&lt;/a&gt;&amp;#8221;&lt;/p&gt;

&lt;p&gt;Dapper用于跟踪大规模分布式系统中的函数调用流程。分布式系统中，一个用户请求通常涉及多级服务、数千模块实例，Dapper可以很适时(一分钟以内)地分析展现用户请求被处理的全流程，包括具体哪一些模块被访问、各级访问延迟、返回值、以及出错细节等等。Dapper在设计中考虑了低消耗、易推广（应用层透明）、以及可扩展性等设计目标。其中应用层透明是最重要最有挑战性的一个目标，设计人员将所有功能在通用的程序库中实现，从而实现了这一目标。&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>memcached的线程模型</title>
   <link href="http://www.baidu-ops.com/2012/08/21/memcached-thread-model"/>
   <updated>2012-08-21T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/08/21/memcached-thread-model</id>
   <content type="html">&lt;h2 id='memcached'&gt;Memcached数据结构&lt;/h2&gt;

&lt;p&gt;memcached的多线程主要是通过实例化多个libevent实现的,分别是一个主线程和n个workers线程。每个线程都是一个单独的libevent实例,主线程eventloop负责处理监听fd，监听客户端的建立连接请求，以及accept连接，将已建立的连接round robin到各个worker。workers线程负责处理已经建立好的连接的读写等事件。”one event loop per thread”.&lt;/p&gt;

&lt;p&gt;首先看下主要的数据结构&lt;/p&gt;

&lt;p&gt;&lt;code&gt;thread.c&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;CQ_ITEM是主线程accept后返回的已建立连接的fd的封装。&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;CQ是一个管理CQ_ITEM的单向链表 Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;LIBEVENT_THREAD 是memcached里的线程结构的封装，可以看到每个线程都包含一个CQ队列，一条通知管道pipe和一个libevent的实例event_base。&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;Memcached对每个网络连接的封装conn&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp memcached主要通过设置/转换连接的不同状态，来处理事件（核心函数是drive_machine，连接的状态机）。&lt;/p&gt;

&lt;h2 id='memcached'&gt;Memcached线程处理流程&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;Memcached.c&lt;/code&gt; 里main函数，先对主线程的libevent实例进行初始化, 然后初始化所有的workers线程，并启动。接着主线程调用server_socket（这里只分析tcp的情况）创建监听socket，绑定地址，设置非阻塞模式并注册监听socket的libevent 读事件等一系列操作。最后主线程调用event_base_loop接收外来连接请求。&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;最后看看memcached网络事件处理的最核心部分- drive_machine drive_machine是多线程环境执行的，主线程和workers都会执行drive_machine。&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;drive_machine主要是通过当前连接的state来判断该进行何种处理，因为通过libevent注册了读写事件后回调的都是这个核心函数，所以实际上我们在注册libevent相应事件时，会同时把事件状态写到该conn结构体里，libevent进行回调时会把该conn结构作为参数传递过来，就是该方法的形参。 连接的状态枚举如下。&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;实际对于case conn_listening:这种情况是主线程自己处理的，workers线程永远不会执行此分支我们看到主线程进行了accept后调用了&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;这个函数就是通知workers线程的地方，看看&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp 可以清楚的看到，主线程首先创建了一个新的CQ_ITEM，然后通过round robin策略选择了一个thread并通过cq_push将这个CQ_ITEM放入了该线程的CQ队列里，那么对应的workers线程是怎么知道的呢? 就是通过 Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;向该线程管道写了1字节数据，则该线程的libevent立即回调了thread_libevent_process方法（上面已经描述过）。 然后那个线程取出item,注册读时间，当该条连接上有数据时，最终也会回调drive_machine方法，也就是drive_machine方法的 case conn_read:等全部是workers处理的，主线程只处理conn_listening 建立连接这个。 memcached的这套多线程event机制很值得设计linux后端网络程序时参考。&lt;/p&gt;

&lt;h2 id='id110'&gt;参考文献&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href='http://www.iteye.com/topic/344172'&gt;memcache源码分析&amp;#8211;线程模型&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;a href='http://blog.csdn.net/bokee/article/details/6670550'&gt;memcached结构分析——线程模型&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;a href='http://basiccoder.com/thread-model-and-state-machine-of-memcached.html'&gt;Memcached的线程模型及状态机&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>
 </entry>
 
 <entry>
   <title>系统优化--磁盘缓存放入内存</title>
   <link href="http://www.baidu-ops.com/2012/08/21/disk-to-memory"/>
   <updated>2012-08-21T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/08/21/disk-to-memory</id>
   <content type="html">&lt;h2 id='id98'&gt;背景&lt;/h2&gt;

&lt;p&gt;News浏览架构升级到lamp后开启了apache的磁盘缓存，使用了eacc加速器，并使用eacc对数据进行了缓存。这些缓存数据并不是放在内存中，而是放在了磁盘上，缓存的频繁读写使得磁盘IO开销很大，cpu-wa达到10~15。另一方面，线上服务器硬件配置越来越高，前端机器的内存高达48甚至64G，只部署webserver的前端机器为cpu和网络消耗型，内存使用率低于50%。因此，希望将前端机器的磁盘缓存放入闲置的内存中，一可以提升内存的利用率，二则可以提升机器的极限处理性能。 调整部署方案是一个办法，修改apache或者php的相关配置，将缓存放入内存也是一种可能的解决办法，但，恰好OP在了解内存文件系统的东西，因此如果能将磁盘缓存目录放入内存文件系统中，会是简单易行的。&lt;/p&gt;

&lt;h2 id='id99'&gt;名词解释&lt;/h2&gt;

&lt;p&gt;内存文件系统：使用内存作为存储介质，并充分发挥内存特性的一类文件系统&lt;/p&gt;

&lt;h2 id='id100'&gt;内存文件系统调研&lt;/h2&gt;

&lt;p&gt;内存文件系统可以直接通过简单mount的方式把内存分配一块出来虚拟成文件系统直接使用，这就提供了一种不修改程序、配置的情况下，将普通文件系统里的数据直接放进内存的方法。如下为一些参考资料：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href='http://www.ibm.com/developerworks/cn/linux/l-linux-filesystem/#N10208'&gt;文件系统剖析&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;现有的内存文件系统介绍&lt;a href='http://linux.net527.cn/Linuxwendang/xitongguanliyuan/1926.html'&gt;tmpfs、ramfs、ramdisk、proc&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id='tmpfs'&gt;TmpFS优缺点&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;需要内核支持，2.4以上版本已经支持；&lt;/li&gt;

&lt;li&gt;mount即可完成，构架在linux虚拟内存管理基础之上的，因此数据有可能在内存，也有可能在交换分区中。重启后文件系统不在存在，数据会丢失，需要重新mount，可以配置在fstab里，启动便加载；&lt;/li&gt;

&lt;li&gt;&lt;a href='http://jinbangli.blog.163.com/blog/static/115625352200932382517151/'&gt;支持设定文件系统大小&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id='ramfs'&gt;RamFS优缺点&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;mount即可完成&lt;/li&gt;

&lt;li&gt;重启后数据丢失。重启后文件系统不在存在，需要重新mount，可以配置在fstab里，启动便加载 3. 不支持设定文件系统大小，占用大小动态增长，有内存耗尽的风险&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id='ramdisk'&gt;RamDisk&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;需要格式化内存，格式化为ext2或其他&lt;/li&gt;

&lt;li&gt;然后mount&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id='id101'&gt;结论&lt;/h4&gt;

&lt;p&gt;内存文件系统不需要读取硬盘，只读取内存，也就是使IO的等待时间、平均排队时间、对列大小等减低，提高吞吐率，节省出的IO时间，就是提升了服务时间。ramdisk需要格式化,ramfs占用空间大小不可控,因此选择tmpfs。&lt;/p&gt;

&lt;h2 id='id102'&gt;部署方法及测试&lt;/h2&gt;

&lt;h4 id='id103'&gt;部署方法&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;建立一个目录&lt;code&gt;/mnt/tmpfs&lt;/code&gt;，以tmpfs文件系统格式mount到&lt;code&gt;/mnt/tmpfs&lt;/code&gt;,指定使用最大内存&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;用df -h 来检查是否正确.如果mount成功后,该目录大小是10G&lt;/li&gt;

&lt;li&gt;使用free 来查看内存使用情况&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id='id104'&gt;测试对比&lt;/h4&gt;

&lt;p&gt;通过对比普通的磁盘文件和tmpfs文件来比较其读写性能。/mnt/tmp为普通的文件目录，/mnt/tmpfs为tmpfs文件系统目录，/dev/shm也为tmpfs文件系统。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;写普通文件到普通文件，速率：15.153 MB/秒&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;普通文件到tmpfs文件，速率：32.7 MB/秒&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;32写tmpfs文件到普通文件，速率：32.2 MB/秒&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;写tmpfs文件到tmpfs文件，速率：64.2 MB/秒&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;h2 id='id105'&gt;线上实际情况&lt;/h2&gt;

&lt;h4 id='id106'&gt;部署与性能测试&lt;/h4&gt;

&lt;p&gt;16台48G前端机器，各开辟了1个20G大小的tmpfs文件系统。测试数据在下一小节中详细阐述。&lt;/p&gt;

&lt;h4 id='id107'&gt;性能表现&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;每秒写磁盘次数对比：1100 -&amp;gt; 5 (次) &lt;img alt='write_performance_times' src='/assets/themes/twitter/bootstrap/img/disk-to-memory/write_performance_times.png' /&gt;&lt;/li&gt;

&lt;li&gt;每秒写数据量对比 ：8100 -&amp;gt; 50 (KB) &lt;img alt='write_performance_Bytes' src='/assets/themes/twitter/bootstrap/img/disk-to-memory/write_performance_Bytes.png' /&gt;&lt;/li&gt;

&lt;li&gt;每秒写磁盘扇区数对比 : 11000 -&amp;gt; 200 (块) &lt;img alt='write_performance_block' src='/assets/themes/twitter/bootstrap/img/disk-to-memory/write_performance_block.png' /&gt;&lt;/li&gt;

&lt;li&gt;每个IO的平均服务时间：0.85 -&amp;gt; 0.14 (ms) &lt;img alt='service_time' src='/assets/themes/twitter/bootstrap/img/disk-to-memory/service_time.png' /&gt;&lt;/li&gt;

&lt;li&gt;每个IO任务等待时间 : 110 -&amp;gt; 1.5 (ms) &lt;img alt='io_wait' src='/assets/themes/twitter/bootstrap/img/disk-to-memory/io_wait.png' /&gt;&lt;/li&gt;

&lt;li&gt;cpu-wa : 12% -&amp;gt; 0% &lt;img alt='cpu_wa' src='/assets/themes/twitter/bootstrap/img/disk-to-memory/cpu_wa.png' /&gt;&lt;/li&gt;

&lt;li&gt;cpu-Idle : 83% -&amp;gt; 93% &lt;img alt='cpu_idle' src='/assets/themes/twitter/bootstrap/img/disk-to-memory/cpu_idle.png' /&gt;&lt;/li&gt;

&lt;li&gt;php响应时间： 23 -&amp;gt; 21 ms&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img alt='response_time' src='/assets/themes/twitter/bootstrap/img/disk-to-memory/response_time.png' /&gt;&lt;/p&gt;

&lt;h2 id='id108'&gt;风险控制&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;tmpfs已经用于linuxnux内核的启动，因此成熟稳定可靠。&lt;/li&gt;

&lt;li&gt;tmpfs支持文件系统空间大小设置，从而排除缓存将内存耗尽引起机器死机的风险，另外，对文件系统添加监控，提前预防的方式也更一步保证了风险可控。&lt;/li&gt;

&lt;li&gt;tmpfs失效后，原ext2目录仍然存在，因此服务仍然可用，并不会因tmpfs失效而直接引发服务问题。&lt;/li&gt;

&lt;li&gt;将tmpfs文件系统的mount等步骤放在rc.local中，以备机器重启后自动mount生效。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id='id109'&gt;结论&lt;/h2&gt;

&lt;p&gt;在net527ws的前端机器用上后效果显著，完成了空间换时间的一次典型实践：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;挖掘闲置内存，使内存使用率提升30%；&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;减少磁盘IO 98%以上，平均读写速度提升85%以上：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;每秒写磁盘次数由1100次降为5次；&lt;/li&gt;

&lt;li&gt;每秒写数据量由8100KB降为50KB；&lt;/li&gt;

&lt;li&gt;每秒写磁盘扇区数由11000块降为200块；&lt;/li&gt;

&lt;li&gt;每个IO的平均服务时间由850ns降为140ms；&lt;/li&gt;

&lt;li&gt;每个IO任务等待时间由110ms降为了1.5 ms；&lt;/li&gt;

&lt;li&gt;降低CPU-WA消耗：CPU-WA由15%降为了0%；&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;提升了机器性能，(单机极限压力提升5~8%：CPU-WA节省带来的CPU收益使得单机极限压力提升5~8% * 降低磁盘文件系统异常的几率：使用内存文件系统后磁盘文件系统报警基本不再发生&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content>
 </entry>
 
 <entry>
   <title>荐文二则</title>
   <link href="http://www.baidu-ops.com/2012/08/21/articles-1"/>
   <updated>2012-08-21T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/08/21/articles-1</id>
   <content type="html">&lt;h3 id='id97'&gt;第一篇是非技术的&lt;/h3&gt;

&lt;p&gt;是李开复几年前作的关于“怎样成为一个出色的演讲家”的报告。&lt;a href='http://t.cn/a8aMg0'&gt;视频&lt;/a&gt; ,&lt;a href='http://t.cn/Shskrb'&gt;PPT&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;报告分为三个部分:&lt;/p&gt;

&lt;p&gt;1. 演讲的技巧&lt;/p&gt;

&lt;p&gt;2. 怎样安排组织演讲的内容&lt;/p&gt;

&lt;p&gt;3. 怎样准备演讲和回答问题&lt;/p&gt;

&lt;p&gt;它跟百度学院的&amp;#8221;&lt;a href='http://www.amazon.cn/金字塔原理-巴巴拉·明托/dp/B0034KYHDE'&gt;金字塔原理&lt;/a&gt;”课程的侧重点不太一样，“金字塔原理”侧重内容的组织，李的报告则包括很多比较实用的演讲技巧，而且视频中有很多有趣的实战的例子，很有可看性。&lt;/p&gt;

&lt;h3 id='googlesigkdd2010'&gt;第二篇是Google在SIGKDD’2010发表的论文&lt;/h3&gt;

&lt;p&gt;&lt;a href='http://research.google.com/pubs/pub36500.html'&gt;Overlapping Experiment Infrastructure: More, Better, Faster Experimentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Google和百度这样大公司，拥有大量的用户，一些产品的规模非常大，需要很多针对新策略的实验。这篇文章讲述了Google的实验环境怎样做 到:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;More（同时进行更多的实验）&lt;/li&gt;

&lt;li&gt;Better（更佳的实验效果以及更及时的错误发现和下线）&lt;/li&gt;

&lt;li&gt;Faster（能快速建立并启动实验） 三个目标&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其主要思想是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;将待实验参数划分为独立的多个子集，每个子集中实验参数是会可能相互影响的，对应于实验环境中的一个layer。这样不同layer中的多个实验可以使用 同样的流量同时进行。&lt;/li&gt;

&lt;li&gt;除了layer，还定义了domain（流量的划分）和experiment（具体的包含在layer中的实验）两个概念。&lt;/li&gt;

&lt;li&gt;通过layer和domain的嵌套组合对很多实验进行灵活控制。&lt;/li&gt;
&lt;/ul&gt;</content>
 </entry>
 
 <entry>
   <title>MFS master的核心数据结构及内存分配简析</title>
   <link href="http://www.baidu-ops.com/2012/08/18/mfs-master-core-structrue"/>
   <updated>2012-08-18T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/08/18/mfs-master-core-structrue</id>
   <content type="html">&lt;h2 id='fsnode'&gt;fsnode&lt;/h2&gt;

&lt;p&gt;我们都知道在linux文件系统中有inode这个概念，inode是文件的索引节点，其中包含了：inode编号，文件的链接数目，属主的UID，属主的组ID (GID)，文件的大小，文件所使用的磁盘块的实际数目，最近一次修改的时间(ctime)，最近一次访问的时间(atime)，最近一次更改的时间(mtime)等等。虚拟文件系统通过inode来访问磁盘中的实际数据块。并返回给应用层。&lt;/p&gt;

&lt;p&gt;MFS系统维护着一个树状文件系统，这个文件系统里面的每个文件是由fsnode来唯一标示的。以下是fsnode的struct构成：&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;其中的id代表fsnode的id号,ctime,atime,mtime代表文件的修改访问时间,goal代表了该文件的拷贝数(默认是3)等等,其中值得重点讲述的是data,我们可以看到这个结构是个union,它是ddata,sdata,fdata三者其中的一个,而这三个不同的struct分别代表这目录,链接,和文件三种不同的属性.某个具体的文件只能对应其中的一种属性.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ddata&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fsedge（留待后文）
nlink：被链接的次数
elements：该目录下的文件数
tatsrecord：统计操作次数&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;sdata&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pleng：路径名长度
path：路径名&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;fdata&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;length：文件名长度
chunktab：文件所存储的文件块索引
chunks：文件所包含的文件块数量&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中我们最关心的当然就是chunktab了，因为它存储了某个文件对应的chunkid，在上图中我们可以看到，chunktab是一个整形数组指针，他存储了具体的chunkid，而这个chunkid是MFS中每一个chunk的唯一标识。&lt;/p&gt;

&lt;h2 id='chunk'&gt;chunk&lt;/h2&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;以上代码是chunk的具体结构，其中chunkid是一个长整形，version是chunk的版本，goal是chunk的拷贝数，allvalidcopies是chunk的所有可用拷贝数目，lockto是此chunk在被写入或修改的时候会被锁住一定的时间。&lt;/p&gt;

&lt;p&gt;需要重点提及的是里面的两个数据结构，slisthead和flisthead，我们知道，MFS同GFS一样，会把每个文件会分成64MB大小的块（某个块的实际存储不够64MB的时候会存储其他文件，直到达到64MB为止），并根据用户设定的拷贝数存储在各个chunkserver上面。所以一个chunk最重要的信息有两个，一个是这个chunk包含了哪一些文件？另一个是哪些chunkserver上有这个chunk?&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;flist是这个chunk拥有的文件列表。它通过文件inode号，和索引位置indx来唯一标识，并且通过一个链表来管理所有的flist。&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;slist就是这个chunk分布在的chunkserver服务器的列表，ptr这个空指针包含了chunkserver的信息，包括ip，port等等，当需要的时候master通过函数matocsserv_getlocation（）来获取这些信息。&lt;/p&gt;

&lt;p&gt;我们看到了客户端通过inode号来获取fsnode的信息，并且在需要发生实际数据IO的时候通过fsnode中对应的chunk列表来获取文件的物理存储位置，并读取文件数据。那么在master服务器中，这些信息是怎么存储的呢？&lt;/p&gt;

&lt;p&gt;答案是：哈希链表。&lt;/p&gt;

&lt;p&gt;哈希链表是linux内核中常常使用的一种数据结构，具体实现是一个哈希表，而这个表中的每个元素都是一个链表的表头。&lt;/p&gt;

&lt;p&gt;每次添加新的fsnode的时候，系统首先会计算出一个hash表中的位置，然后把这个新添的fsnode添加在表头。同样的结构也应用在chunk以及fsedge上面。&lt;/p&gt;

&lt;h2 id='fsedge'&gt;fsedge&lt;/h2&gt;

&lt;p&gt;fsedge的实现如下所示&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;我们上文提到，mfs维护了一个树状文件系统，而我们也看到fsnode本身并没有实现这种关联关系。fsedge的作用就是对整个文件系统中的fsnode建立树状逻辑关系。&lt;/p&gt;

&lt;p&gt;fsnode之间并不是直接连接的，而是通过fsedge来建立逻辑关系。当我们需要用到这些目录信息，比如列出某个目录底下全部文件，计算某个目录下的文件大小等等的时候fsedge就能派上用场了。&lt;/p&gt;

&lt;p&gt;至此，关于MFS的一些核心数据结构的设计，实现以及他们在内存中的分布我们的介绍就全部结束了。&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>一名运维工程师的读书列表</title>
   <link href="http://www.baidu-ops.com/2012/08/01/ops-book-list"/>
   <updated>2012-08-01T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/08/01/ops-book-list</id>
   <content type="html">&lt;p&gt;&lt;img alt='bookself' src='/assets/themes/twitter/bootstrap/img/bookself.jpg' /&gt;&lt;/p&gt;

&lt;p&gt;做应用运维这一行，读了一些书,从好书里面学到了不少知识。希望这个书单不断变长。&lt;/p&gt;

&lt;p&gt;&lt;a href='http://www.stackoverflow.com'&gt;stackoverflow&lt;/a&gt;上面列出了一名程序员都应该学习的&lt;a href='http://stackoverflow.com/questions/1711/what-is-the-single-most-influential-book-every-programmer-should-read?tab=votes#tab-top'&gt;书单&lt;/a&gt;,这是&lt;a href='http://book.douban.com/doulist/1244005/'&gt;中文版&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;我把书分为3类：技术， 技术文化， 外延&lt;/p&gt;

&lt;h2 id='id94'&gt;技术文化读本：&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/1152111/'&gt;程序员修炼之道&lt;/a&gt;里面的思想不仅适合开发，也适合运维。印象最深的是“正交设计”和“K.I.S.S.原则”&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/4163938/'&gt;软件随想录&lt;/a&gt;joel带给你不同的思路，从不同的角度看软件和软件文化另外一本他之前出版的文集&lt;a href='http://book.douban.com/subject/2193777/'&gt;joel谈优秀软件开发方法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/6021440/'&gt;黑客与画家&lt;/a&gt;关于互联网公司和软件的特点；设计；编程语言。java &amp;lt; python &amp;lt; perl &amp;lt; ruby &amp;lt; lisp 给我印象很深，坚定了我学习ruby和了解lisp的信心。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/1467587/'&gt;unix编程艺术&lt;/a&gt;在unix平台上工作，但对unix的开发和设计哲学不了解，转而采用windows的方式，做了很多额外的工作而没抓住本质。此书必读。另外近期出版了一本&lt;a href='http://www.amazon.cn/gp/product/B007PYVKLC/ref=oh_details_o01_s00_i00'&gt;linux/unix设计思想&lt;/a&gt;也可以读一读。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/4031959/'&gt;软件开发沉思录&lt;/a&gt;能学到很多新奇的想法：关于“软件开发最后一英里”，ruby，多语言开发，配置文件重构，一键发布，性能测试的探讨一针见血。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://www.amazon.cn/gp/product/B0048EKQS0/ref=oh_details_o03_s00_i00'&gt;rework&lt;/a&gt;极简的思想，并应用于产品开发和工程实现。非常棒。很多工程师都把简单的问题搞复杂。此书必须要读一读。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/1135754/'&gt;你的灯亮着吗？&lt;/a&gt;关于问题的一本书。当中一句话受益匪浅“问题只能转化而不能被解决”。值得反复读。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject_search?search_text=%E6%B8%A9%E4%BC%AF%E6%A0%BC&amp;amp;cat=1003'&gt;杰拉尔德•温伯格(Gerald M.Weinberg)&lt;/a&gt; 的书思想都很深邃，有兴趣可以读一读。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id='id95'&gt;技术上的书籍：&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/1333125/'&gt;unix超级工具(上/下册)&lt;/a&gt;非常棒。都是老一批骨灰级用户多年经验的结晶。每一个专题都需要反复阅读，并亲身实践。对于刚接触linux的人必须反复研读。才能了解unix设计的要点。读得多了就觉得unix是一个非常优雅的设计。还有一本开源的讲bash的书：&lt;a href='http://tldp.org/LDP/abs/html/'&gt;abs&lt;/a&gt;,bash学习必备的书，讲得很透彻，了解shell，通过shell熟悉linux的运行机制。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/2580604/'&gt;持续集成&lt;/a&gt;敏捷开发的最重要实践之一。软件工程的重要思想。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/6862062/'&gt;持续交付&lt;/a&gt;和上一本书思想一致，更切实与op的实际。一定要从产品研发周期看问题，不能仅看运维。开发和运维剁得越开，运维越是不好做。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/1238125/'&gt;unix和linux自动化管理&lt;/a&gt;老牌系统管理员的经验总结。书读得比较早了，印象最深的就是对数据推和拉的分析。还有一点印象比较深，如何设计shell脚本的配置文件。注意体会作者的思路，对问题的权衡。书中也有很多代码片段。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/2154713/'&gt;精通正则表达式&lt;/a&gt;经典。正则是非常美的DSL，perl是所有语言中正则和语言本体结合最紧密，最好用的语言。虽然后来喜欢ruby，但这一点仍然是perl的特色。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/3063982/'&gt;perl最佳实践&lt;/a&gt;如果在用perl，则在写真实的程序之前，一定要读perl的设计很灵活，遵循一定的约束，写出来的代码才能读。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/1236944/'&gt;sed和awk&lt;/a&gt;系统管理员必备工具。对awk把对文本一行一行的读取，这样一个大循环内置于工具所体现出来的表述上的简洁，非常震撼。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/1232029/'&gt;C专家编程&lt;/a&gt;非常有趣的一本书。给读者展现了C设计的一些优缺点，如何更好的使用C。对系统底层的理解也能加深。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://product.china-pub.com/196374'&gt;重构&lt;/a&gt;这本书我读过一点，书上的实例亲手操作了一下，非常cool。把code写好，写棒，不容易。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://www.amazon.cn/mn/detailApp?uid=479-6704744-9217618&amp;amp;ref=YS_TR_6&amp;amp;asin=B005KGBTQ8'&gt;松本行弘的程序世界&lt;/a&gt;了解ruby的设计折中，为何要采取此种class和module的继承机制，block的设计都做了哪些考虑和折中。体会他的思想。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://www.amazon.cn/Ruby%E5%85%83%E7%BC%96%E7%A8%8B-Paolo-Perrotta/dp/B0073APSCK/ref=pd_sim_b_2'&gt;ruby元编程&lt;/a&gt;信息量比较大。ruby的得体的设计，使它真的非常适合程序员使用。看完元编程后我就深深喜欢ruby了。真的简单，优雅。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id='id96'&gt;其他读本&lt;/h2&gt;

&lt;p&gt;有益于提升自己能力。在另一个领域的知识能够很好的补充正在从事的专业领域的知识。比如：设计，中医给我的触动比较深。他们背后和unix所体现出来的，差不多。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href='http://book.douban.com/subject/3313363/'&gt;演说之禅&lt;/a&gt;读完这本书，我很少再使用ppt的自带动画。都采用翻页的形式。ppt仅展现更简单的信息。简单就是美。所有讲ppt设计的书，这本最好。&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://product.china-pub.com/676957'&gt;走近中医&lt;/a&gt;中医也是一个系统，可以类比unix。每个部分之间的关系紧凑，严谨，并且是辩证的。有利于形成系统思考的方法。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content>
 </entry>
 
 <entry>
   <title>用Jekyll写技术博客</title>
   <link href="http://www.baidu-ops.com/2012/07/11/jekyll"/>
   <updated>2012-07-11T00:00:00+02:00</updated>
   <id>http://www.baidu-ops.com/2012/07/11/jekyll</id>
   <content type="html">&lt;h2 id='id92'&gt;缘由&lt;/h2&gt;

&lt;p&gt;曾经也有过写技术博客的冲动。申请过bloger，msn space。但总觉得这些blog如果写一些日常的感受还可以，但总是让人不能专注于写作，很小的编辑框，还要时刻注意换行，稍不注意，显示的格式就不对了。&lt;/p&gt;

&lt;p&gt;直到最近，我在&lt;a href='http://www.yangzhiping.com/tech/writing-space.html'&gt;一篇blog&lt;/a&gt;上知道了－－&lt;a href='http://jekyllrb.com/'&gt;Jekyll&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;老外写书已经采用编程和项目的方式了, &lt;a href='http://pragprog.com/'&gt;The Pragmatic Bookshelf&lt;/a&gt; 的书都是这么写出来的，通过git做版本管理，通过Rake执行图书排版，甚至通过hudson进行每次提交进行排版。&lt;/p&gt;

&lt;p&gt;Jekyll时ruby的一个项目。允许通过git进行版本管理，托管在github上作为一个项目。并通过静态页面进行访问。&lt;a href='http://tom.preston-werner.com'&gt;Tom&lt;/a&gt;是Jekyll的作者，同时也是&lt;a href='http://www.github.com'&gt;github&lt;/a&gt;的创始人，&lt;a href='http://tom.preston-werner.com/2008/11/17/blogging-like-a-hacker.html'&gt;这篇文章&lt;/a&gt;中Tom介绍了开发jekyll的初衷。&lt;/p&gt;

&lt;h2 id='id93'&gt;使用&lt;/h2&gt;

&lt;p&gt;更详细的使用步骤参见&lt;a href='http://jekyllbootstrap.com/'&gt;这里&lt;/a&gt;&lt;/p&gt;

&lt;h3 id='post'&gt;写post&lt;/h3&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;h3 id='preview'&gt;本地preview&lt;/h3&gt;

&lt;p&gt;在_post目录中完成编辑，使用vim 本地启动server，进行预览,如果在预览的过程中又对文件进行了编辑，会动态生成新的网页。&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;h3 id='github'&gt;提交到github&lt;/h3&gt;

&lt;p&gt;将文章提交到github上。如果使用了github提供的个人主页服务，则提交之后即能够访问。首先要创建一个 “&lt;a href='http://github.com/zerdliu/zerdliu.github.com'&gt;用户名.github.com&lt;/a&gt;”的仓库.具体步骤&lt;a href='http://jekyllbootstrap.com/usage/deployment-and-hosting.html'&gt;参见&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;h3 id='ftp'&gt;通过ftp自动发布&lt;/h3&gt;

&lt;p&gt;如果不是使用github提供的个人主页服务，使用自己托管的空间，通过ftp上传，可以通过下面的方式完成网站的部署&lt;/p&gt;

&lt;p&gt;&lt;code&gt;_deploy.sh&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp 然后执行&lt;/p&gt;

&lt;p&gt;Liquid error: No such file or directory - posix_spawnp&lt;/p&gt;

&lt;p&gt;就完成blog的发布 可以把发布脚本写在git的post commit hook里面，但是我更习惯于多次提交，一次push，一次deploy的节奏。&lt;/p&gt;

&lt;p&gt;&lt;a href='http://markdown.tw/'&gt;markdown&lt;/a&gt;格式类似于wiki格式又不同于wiki编写，比wiki的语法更简单，也够用了。 非常适合在vim中进行编辑，可以将注意力集中在写作上，不再分散精力。文章托管在github上，如果是重要一点的内容，可以申请付费的repo，托管私有项目。通过git进行版本管理，不再担心写错，想到哪，写到哪。也方便做备份。&lt;/p&gt;</content>
 </entry>
 
 
</feed>